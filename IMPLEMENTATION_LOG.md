# –ñ—É—Ä–Ω–∞–ª –∏–º–ø–ª–µ–º–µ–Ω—Ç–∞—Ü–∏–∏

**–ü—Ä–æ–µ–∫—Ç:** Semantic Contamination - Tier 1 Upgrades
**–ù–∞—á–∞–ª–æ:** 2025-11-15
**–°—Ç–∞—Ç—É—Å:** –í –ø—Ä–æ—Ü–µ—Å—Å–µ

---

## –§–æ—Ä–º–∞—Ç –∑–∞–ø–∏—Å–µ–π

–ö–∞–∂–¥–∞—è –∑–∞–ø–∏—Å—å —Å–æ–¥–µ—Ä–∂–∏—Ç:
- **–î–∞—Ç–∞ –∏ –≤—Ä–µ–º—è**
- **–®–∞–≥** (—Å–æ–≥–ª–∞—Å–Ω–æ IMPLEMENTATION_PLAN.md)
- **–ß—Ç–æ —Å–¥–µ–ª–∞–Ω–æ**
- **–ü–æ—á–µ–º—É —ç—Ç–æ —Å–¥–µ–ª–∞–Ω–æ** (–æ–±–æ—Å–Ω–æ–≤–∞–Ω–∏–µ)
- **–ö–∞–∫ —ç—Ç–æ —Å–¥–µ–ª–∞–Ω–æ** (—Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ –¥–µ—Ç–∞–ª–∏)
- **–ü—Ä–æ–±–ª–µ–º—ã –∏ —Ä–µ—à–µ–Ω–∏—è**
- **–°—Å—ã–ª–∫–∏ –Ω–∞ —Ñ–∞–π–ª—ã/–∫–æ–º–º–∏—Ç—ã**

---

## 2025-11-15

### [14:00] –°–æ–∑–¥–∞–Ω–∏–µ –ø–ª–∞–Ω–∞ –∏ –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏

**–®–∞–≥:** –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞
**–°—Ç–∞—Ç—É—Å:** ‚úÖ –ó–∞–≤–µ—Ä—à–µ–Ω–æ

**–ß—Ç–æ —Å–¥–µ–ª–∞–Ω–æ:**
- –°–æ–∑–¥–∞–Ω IMPLEMENTATION_PLAN.md —Å –¥–µ—Ç–∞–ª—å–Ω—ã–º –ø–ª–∞–Ω–æ–º –Ω–∞ 10 —à–∞–≥–æ–≤
- –°–æ–∑–¥–∞–Ω IMPLEMENTATION_LOG.md (—ç—Ç–æ—Ç —Ñ–∞–π–ª) –¥–ª—è –¥–æ–∫—É–º–µ–Ω—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
- –ù–∞—Å—Ç—Ä–æ–µ–Ω todo-list –¥–ª—è –æ—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏—è –ø—Ä–æ–≥—Ä–µ—Å—Å–∞

**–ü–æ—á–µ–º—É:**
- –ù–µ–æ–±—Ö–æ–¥–∏–º–∞ —á–µ—Ç–∫–∞—è roadmap –¥–ª—è –∏–º–ø–ª–µ–º–µ–Ω—Ç–∞—Ü–∏–∏
- –î–æ–∫—É–º–µ–Ω—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –≤ –ø—Ä–æ—Ü–µ—Å—Å–µ –∫—Ä–∏—Ç–∏—á–Ω–æ –¥–ª—è future reference
- Todo-list –ø–æ–º–æ–≥–∞–µ—Ç –æ—Ç—Å–ª–µ–∂–∏–≤–∞—Ç—å –ø—Ä–æ–≥—Ä–µ—Å—Å

**–ö–∞–∫:**
- –ü–ª–∞–Ω —Ä–∞–∑–¥–µ–ª–µ–Ω –Ω–∞ 3 —Ñ–∞–∑—ã: –ò–Ω—Ñ—Ä–∞—Å—Ç—Ä—É–∫—Ç—É—Ä–∞, –ê–≥–µ–Ω—Ç—ã, –î–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è
- –ö–∞–∂–¥—ã–π —à–∞–≥ –∏–º–µ–µ—Ç –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç, –æ—Ü–µ–Ω–∫—É –≤—Ä–µ–º–µ–Ω–∏, –∑–∞–¥–∞—á–∏ –∏ –æ–±–æ—Å–Ω–æ–≤–∞–Ω–∏–µ
- –û–±—â–∞—è –æ—Ü–µ–Ω–∫–∞: 26-37 —á–∞—Å–æ–≤ —Ä–∞–±–æ—Ç—ã

**–§–∞–π–ª—ã:**
- IMPLEMENTATION_PLAN.md
- IMPLEMENTATION_LOG.md

---

### [14:30] –®–∞–≥ 1.1: –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ requirements.txt

**–®–∞–≥:** 1 - –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π
**–°—Ç–∞—Ç—É—Å:** üîÑ –í –ø—Ä–æ—Ü–µ—Å—Å–µ

**–ß—Ç–æ —Å–¥–µ–ª–∞–Ω–æ:**
- –ü–æ–¥–≥–æ—Ç–æ–≤–ª–µ–Ω —Å–ø–∏—Å–æ–∫ –Ω–æ–≤—ã—Ö –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π
- –ü—Ä–æ–≤–µ—Ä–µ–Ω–∞ —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç—å –≤–µ—Ä—Å–∏–π

**–ü–æ—á–µ–º—É:**
–¢–µ–∫—É—â–∏–π requirements.txt —Å–æ–¥–µ—Ä–∂–∏—Ç —Ç–æ–ª—å–∫–æ –±–∞–∑–æ–≤—ã–µ –±–∏–±–ª–∏–æ—Ç–µ–∫–∏:
```
pandas>=2.0.0
numpy>=1.24.0
regex>=2023.0.0
python-dateutil>=2.8.0
```

–î–ª—è Tier 1 –∏–º–ø–ª–µ–º–µ–Ω—Ç–∞—Ü–∏–∏ –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã:
1. **LLM APIs** (openai, anthropic) ‚Äî –¥–ª—è —Ä–µ–∞–ª—å–Ω–æ–≥–æ reasoning –≤–º–µ—Å—Ç–æ —ç–≤—Ä–∏—Å—Ç–∏–∫
2. **LangChain** ‚Äî –¥–ª—è ReAct –∏ web search –≤ VerifierAgent
3. **Transformers + torch** ‚Äî –¥–ª—è PairRM –≤ JudgeAgent
4. **SelfCheckGPT** ‚Äî –¥–ª—è –¥–µ—Ç–µ–∫—Ü–∏–∏ –≥–∞–ª–ª—é—Ü–∏–Ω–∞—Ü–∏–π –≤ ExtractorAgent
5. **SerpAPI** ‚Äî –¥–ª—è –≤–µ–±-–ø–æ–∏—Å–∫–∞
6. **python-dotenv** ‚Äî –¥–ª—è –±–µ–∑–æ–ø–∞—Å–Ω–æ–≥–æ —Ö—Ä–∞–Ω–µ–Ω–∏—è API –∫–ª—é—á–µ–π

**–ö–∞–∫:**
–î–æ–±–∞–≤–ª—è–µ–º –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –ø–æ—ç—Ç–∞–ø–Ω–æ —Å –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏—è–º–∏ –¥–ª—è —è—Å–Ω–æ—Å—Ç–∏:

```python
# LLM APIs ‚Äî –æ—Å–Ω–æ–≤–∞ –¥–ª—è reasoning
openai>=1.0.0              # OpenAI GPT-4/3.5
anthropic>=0.3.0           # Claude (–∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–∞)

# Reasoning & Orchestration
langchain>=0.1.0           # Framework –¥–ª—è ReAct, chains
langchain-community>=0.0.38 # Community tools
langchain-openai>=0.0.5    # OpenAI integration

# Models –¥–ª—è –ª–æ–∫–∞–ª—å–Ω–æ–≥–æ inference
transformers>=4.36.0       # HuggingFace transformers (PairRM)
torch>=2.0.0              # PyTorch (backend –¥–ª—è transformers)
sentence-transformers>=2.2.0 # Semantic similarity

# Web search
google-search-results>=2.4.2  # SerpAPI wrapper

# Hallucination detection
selfcheckgpt>=0.1.0       # SelfCheck –¥–ª—è ExtractorAgent

# Utilities
python-dotenv>=1.0.0      # .env —Ñ–∞–π–ª—ã –¥–ª—è API –∫–ª—é—á–µ–π
pydantic>=2.0.0           # –í–∞–ª–∏–¥–∞—Ü–∏—è –¥–∞–Ω–Ω—ã—Ö
tiktoken>=0.5.0           # –¢–æ–∫–µ–Ω–∏–∑–∞—Ü–∏—è –¥–ª—è cost tracking
```

**–ü—Ä–æ–±–ª–µ–º—ã –∏ —Ä–µ—à–µ–Ω–∏—è:**

1. **–ü—Ä–æ–±–ª–µ–º–∞:** Torch –∏–º–µ–µ—Ç –±–æ–ª—å—à–æ–π —Ä–∞–∑–º–µ—Ä (>2GB)
   **–†–µ—à–µ–Ω–∏–µ:** –î–æ–±–∞–≤–∏—Ç—å –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–π –æ CPU-only –≤–µ—Ä—Å–∏–∏ –¥–ª—è production –±–µ–∑ GPU:
   ```bash
   # –î–ª—è CPU-only (–º–µ–Ω—å—à–µ —Ä–∞–∑–º–µ—Ä):
   # pip install torch --index-url https://download.pytorch.org/whl/cpu
   ```

2. **–ü—Ä–æ–±–ª–µ–º–∞:** –í–µ—Ä—Å–∏–∏ LangChain –±—ã—Å—Ç—Ä–æ –º–µ–Ω—è—é—Ç—Å—è
   **–†–µ—à–µ–Ω–∏–µ:** –£–∫–∞–∑–∞—Ç—å –º–∏–Ω–∏–º–∞–ª—å–Ω—ã–µ –≤–µ—Ä—Å–∏–∏ (>=), –Ω–æ —Ä–µ–∫–æ–º–µ–Ω–¥–æ–≤–∞—Ç—å –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ –≤ –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏

3. **–ü—Ä–æ–±–ª–µ–º–∞:** SelfCheckGPT –º–æ–∂–µ—Ç —Ç—Ä–µ–±–æ–≤–∞—Ç—å –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –º–æ–¥–µ–ª–∏
   **–†–µ—à–µ–Ω–∏–µ:** –î–æ–±–∞–≤–∏—Ç—å –≤ –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—é –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏—é –ø–æ —Å–∫–∞—á–∏–≤–∞–Ω–∏—é –º–æ–¥–µ–ª–µ–π

**–°–ª–µ–¥—É—é—â–∏–µ –¥–µ–π—Å—Ç–≤–∏—è:**
- ‚úÖ –û–±–Ω–æ–≤–∏—Ç—å —Ñ–∞–π–ª requirements.txt
- ‚úÖ –°–æ–∑–¥–∞—Ç—å requirements-dev.txt –¥–ª—è development –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π
- ‚úÖ –°–æ–∑–¥–∞—Ç—å .env.example

**–§–∞–π–ª—ã:**
- requirements.txt (–æ–±–Ω–æ–≤–ª–µ–Ω)
- requirements-dev.txt (—Å–æ–∑–¥–∞–Ω)
- .env.example (—Å–æ–∑–¥–∞–Ω)

---

### [15:00] –®–∞–≥ 1.2: –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ .gitignore

**–®–∞–≥:** 1 - –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π
**–°—Ç–∞—Ç—É—Å:** ‚úÖ –ó–∞–≤–µ—Ä—à–µ–Ω–æ

**–ß—Ç–æ —Å–¥–µ–ª–∞–Ω–æ:**
- –û–±–Ω–æ–≤–ª–µ–Ω .gitignore –¥–ª—è –∏—Å–∫–ª—é—á–µ–Ω–∏—è .env —Ñ–∞–π–ª–æ–≤
- –î–æ–±–∞–≤–ª–µ–Ω—ã cache –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏
- –î–æ–±–∞–≤–ª–µ–Ω—ã model —Ñ–∞–π–ª—ã (*.bin, *.pt, *.safetensors)
- –î–æ–±–∞–≤–ª–µ–Ω—ã coverage –∏ –ø—Ä–æ—Ñ–∏–ª–∏—Ä–æ–≤–∞–Ω–∏–µ

**–ü–æ—á–µ–º—É:**
1. **.env —Ñ–∞–π–ª—ã** ‚Äî —Å–æ–¥–µ—Ä–∂–∞—Ç API –∫–ª—é—á–∏, –ö–†–ò–¢–ò–ß–ù–û –Ω–µ –∫–æ–º–º–∏—Ç–∏—Ç—å –≤ git
2. **Cache –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏** ‚Äî –≤—Ä–µ–º–µ–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ, –Ω–µ –Ω—É–∂–Ω—ã –≤ —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–∏
3. **Model —Ñ–∞–π–ª—ã** ‚Äî —Å–∫–∞—á–∏–≤–∞—é—Ç—Å—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏, –æ—á–µ–Ω—å –±–æ–ª—å—à–∏–µ (>1GB)
4. **Coverage/profiling** ‚Äî build artifacts

**–ö–∞–∫:**
–î–æ–±–∞–≤–ª–µ–Ω—ã —Å–µ–∫—Ü–∏–∏:
```gitignore
# Environment variables (CRITICAL: never commit API keys!)
.env
.env.local

# Cache directories
.cache/
.pytest_cache/
.mypy_cache/

# Model files (downloaded on first run)
models/
*.bin
*.pt
*.pth
*.safetensors
```

**–í–∞–∂–Ω–æ:**
- `.env` –≤ blacklist –ø—Ä–µ–¥–æ—Ç–≤—Ä–∞—â–∞–µ—Ç —Å–ª—É—á–∞–π–Ω—ã–π –∫–æ–º–º–∏—Ç API –∫–ª—é—á–µ–π
- Model —Ñ–∞–π–ª—ã –∏—Å–∫–ª—é—á–µ–Ω—ã —Ç.–∫. –æ–Ω–∏ >1GB –∏ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ —Å–∫–∞—á–∏–≤–∞—é—Ç—Å—è –ø—Ä–∏ –ø–µ—Ä–≤–æ–º –∑–∞–ø—É—Å–∫–µ

**–§–∞–π–ª—ã:**
- .gitignore (–æ–±–Ω–æ–≤–ª–µ–Ω)

---

### [15:15] –®–∞–≥ 1.3: –°–æ–∑–¥–∞–Ω–∏–µ src/config.py

**–®–∞–≥:** 1 - –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π
**–°—Ç–∞—Ç—É—Å:** ‚úÖ –ó–∞–≤–µ—Ä—à–µ–Ω–æ

**–ß—Ç–æ —Å–¥–µ–ª–∞–Ω–æ:**
- –°–æ–∑–¥–∞–Ω src/config.py —Å pydantic-based –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–µ–π
- –†–µ–∞–ª–∏–∑–æ–≤–∞–Ω–∞ –≤–∞–ª–∏–¥–∞—Ü–∏—è –≤—Å–µ—Ö –Ω–∞—Å—Ç—Ä–æ–µ–∫
- –î–æ–±–∞–≤–ª–µ–Ω—ã computed properties –¥–ª—è –ø—É—Ç–µ–π
- –î–æ–±–∞–≤–ª–µ–Ω—ã utility —Ñ—É–Ω–∫—Ü–∏–∏ –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ API –∫–ª—é—á–µ–π

**–ü–æ—á–µ–º—É:**
1. **–¶–µ–Ω—Ç—Ä–∞–ª–∏–∑–∞—Ü–∏—è** ‚Äî –≤—Å–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –≤ –æ–¥–Ω–æ–º –º–µ—Å—Ç–µ
2. **–í–∞–ª–∏–¥–∞—Ü–∏—è** ‚Äî pydantic –ø—Ä–æ–≤–µ—Ä—è–µ—Ç —Ç–∏–ø—ã –∏ –∑–Ω–∞—á–µ–Ω–∏—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏
3. **Type safety** ‚Äî IDE autocomplete –∏ type checking
4. **Environment variables** ‚Äî –±–µ–∑–æ–ø–∞—Å–Ω–æ–µ —Ö—Ä–∞–Ω–µ–Ω–∏–µ credentials
5. **Default values** ‚Äî —Ä–∞–±–æ—Ç–∞–µ—Ç out-of-the-box –±–µ–∑ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏

**–ö–∞–∫:**

–°—Ç—Ä—É–∫—Ç—É—Ä–∞ Settings –∫–ª–∞—Å—Å–∞:
```python
class Settings(BaseSettings):
    # API Keys
    OPENAI_API_KEY: Optional[str] = None
    ANTHROPIC_API_KEY: Optional[str] = None
    SERPAPI_API_KEY: Optional[str] = None

    # Model Settings
    DEFAULT_LLM_PROVIDER: Literal["openai", "anthropic"] = "openai"
    DEFAULT_MODEL: str = "gpt-4-turbo-preview"
    TEMPERATURE: float = 0.7
    MAX_TOKENS: int = 2000

    # Agent Settings
    USE_PAIRRM: bool = True
    USE_SELFCHECK: bool = True
    SELFCHECK_SAMPLES: int = 3

    # Paths, Performance, Cache, etc.
    ...
```

**–ö–ª—é—á–µ–≤—ã–µ —Ñ–∏—á–∏:**

1. **Computed Properties:**
   ```python
   @property
   def input_path(self) -> Path:
       return PROJECT_ROOT / self.INPUT_DIR

   @property
   def can_use_llm(self) -> bool:
       return self.has_openai_key or self.has_anthropic_key
   ```

2. **Validators:**
   ```python
   @validator("DEFAULT_MODEL")
   def validate_model(cls, v, values):
       # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏ –º–æ–¥–µ–ª–∏ —Å –ø—Ä–æ–≤–∞–π–¥–µ—Ä–æ–º
       ...
   ```

3. **Utility Functions:**
   ```python
   def validate_api_keys():
       """–ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞–ª–∏—á–∏—è –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã—Ö API –∫–ª—é—á–µ–π"""
       if not settings.can_use_llm:
           raise ValueError(...)

   def print_config():
       """–í—ã–≤–æ–¥ —Ç–µ–∫—É—â–µ–π –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ (–±–µ–∑ —Å–µ–∫—Ä–µ—Ç–æ–≤)"""
       ...
   ```

**–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ:**
```python
from config import settings

# –î–æ—Å—Ç—É–ø –∫ –Ω–∞—Å—Ç—Ä–æ–π–∫–∞–º
print(settings.DEFAULT_MODEL)
print(settings.output_path)

# –ü—Ä–æ–≤–µ—Ä–∫–∞ API –∫–ª—é—á–µ–π
if settings.can_use_llm:
    # Use LLM
    ...

# –í–∞–ª–∏–¥–∞—Ü–∏—è
validate_api_keys()
```

**–ü—Ä–µ–∏–º—É—â–µ—Å—Ç–≤–∞:**
- ‚úÖ Type-safe (mypy –ø—Ä–æ–≤–µ—Ä—è–µ—Ç —Ç–∏–ø—ã)
- ‚úÖ Auto-validation (pydantic –≤–∞–ª–∏–¥–∏—Ä—É–µ—Ç –∑–Ω–∞—á–µ–Ω–∏—è)
- ‚úÖ IDE support (autocomplete –¥–ª—è –≤—Å–µ—Ö –ø–æ–ª–µ–π)
- ‚úÖ Default values (—Ä–∞–±–æ—Ç–∞–µ—Ç –±–µ–∑ .env —Ñ–∞–π–ª–∞)
- ‚úÖ Environment variables (–±–µ–∑–æ–ø–∞—Å–Ω–æ–µ —Ö—Ä–∞–Ω–µ–Ω–∏–µ secrets)

**–§–∞–π–ª—ã:**
- src/config.py (—Å–æ–∑–¥–∞–Ω)

---

### [15:30] –®–∞–≥ 2.1: –°–æ–∑–¥–∞–Ω–∏–µ src/llm/ –º–æ–¥—É–ª—è

**–®–∞–≥:** 2 - –ë–∞–∑–æ–≤–∞—è LLM –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è
**–°—Ç–∞—Ç—É—Å:** üîÑ –í –ø—Ä–æ—Ü–µ—Å—Å–µ

**–ß—Ç–æ –¥–µ–ª–∞–µ–º:**
- –°–æ–∑–¥–∞—ë–º src/llm/__init__.py
- –°–æ–∑–¥–∞—ë–º src/llm/llm_client.py —Å –∞–±—Å—Ç—Ä–∞–∫—Ü–∏–µ–π –¥–ª—è LLM API
- –î–æ–±–∞–≤–ª—è–µ–º –ø–æ–¥–¥–µ—Ä–∂–∫—É OpenAI –∏ Anthropic —Å –µ–¥–∏–Ω—ã–º –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å–æ–º
- –†–µ–∞–ª–∏–∑—É–µ–º error handling, retry logic, rate limiting, cost tracking

**–ü–æ—á–µ–º—É:**
–¢–µ–∫—É—â–∏–µ –∞–≥–µ–Ω—Ç—ã –∏—Å–ø–æ–ª—å–∑—É—é—Ç —ç–≤—Ä–∏—Å—Ç–∏–∫–∏ –≤–º–µ—Å—Ç–æ —Ä–µ–∞–ª—å–Ω–æ–≥–æ LLM reasoning.
–ù—É–∂–Ω–∞ –µ–¥–∏–Ω–∞—è –∞–±—Å—Ç—Ä–∞–∫—Ü–∏—è –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å —Ä–∞–∑–Ω—ã–º–∏ LLM –ø—Ä–æ–≤–∞–π–¥–µ—Ä–∞–º–∏:
- OpenAI (GPT-4, GPT-3.5)
- Anthropic (Claude)
- –í–æ–∑–º–æ–∂–Ω–æ—Å—Ç—å –¥–æ–±–∞–≤–ª–µ–Ω–∏—è –¥—Ä—É–≥–∏—Ö (Cohere, local models)

–¢—Ä–µ–±–æ–≤–∞–Ω–∏—è:
1. **–ï–¥–∏–Ω—ã–π –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å** ‚Äî –æ–¥–∏–Ω–∞–∫–æ–≤—ã–π API –¥–ª—è –≤—Å–µ—Ö –ø—Ä–æ–≤–∞–π–¥–µ—Ä–æ–≤
2. **Error handling** ‚Äî retry –Ω–∞ transient errors (rate limits, timeouts)
3. **Cost tracking** ‚Äî –æ—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏–µ —Ä–∞—Å—Ö–æ–¥–æ–≤
4. **Rate limiting** ‚Äî –Ω–µ –ø—Ä–µ–≤—ã—à–∞—Ç—å –ª–∏–º–∏—Ç—ã API
5. **Caching** ‚Äî –Ω–µ –¥–µ–ª–∞—Ç—å –¥—É–±–ª–∏—Ä—É—é—â–∏–µ –≤—ã–∑–æ–≤—ã

**–ö–∞–∫:**

–ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞:
```
src/llm/
‚îú‚îÄ‚îÄ __init__.py          # –≠–∫—Å–ø–æ—Ä—Ç—ã
‚îú‚îÄ‚îÄ base.py              # –ë–∞–∑–æ–≤—ã–π –∫–ª–∞—Å—Å LLMClient
‚îú‚îÄ‚îÄ openai_client.py     # OpenAI implementation
‚îú‚îÄ‚îÄ anthropic_client.py  # Anthropic implementation
‚îú‚îÄ‚îÄ cost_tracker.py      # –û—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏–µ —Å—Ç–æ–∏–º–æ—Å—Ç–∏
‚îî‚îÄ‚îÄ utils.py             # Utility —Ñ—É–Ω–∫—Ü–∏–∏
```

**–ò–Ω—Ç–µ—Ä—Ñ–µ–π—Å:**
```python
class LLMClient(ABC):
    @abstractmethod
    def generate(self, prompt: str, **kwargs) -> LLMResponse:
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Ç–µ–∫—Å—Ç–∞"""

    @abstractmethod
    def count_tokens(self, text: str) -> int:
        """–ü–æ–¥—Å—á–µ—Ç —Ç–æ–∫–µ–Ω–æ–≤"""

    def get_stats(self) -> Dict[str, Any]:
        """–ü–æ–ª—É—á–∏—Ç—å —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è"""
```

**–°—Ç–∞—Ç—É—Å:** ‚úÖ –ó–∞–≤–µ—Ä—à–µ–Ω–æ

**–ß—Ç–æ —Å–¥–µ–ª–∞–Ω–æ:**
- ‚úÖ –°–æ–∑–¥–∞–Ω –ø–æ–ª–Ω—ã–π –º–æ–¥—É–ª—å src/llm/
- ‚úÖ OpenAIClient —Å retry logic –∏ cost tracking
- ‚úÖ AnthropicClient —Å –∞–Ω–∞–ª–æ–≥–∏—á–Ω—ã–º —Ñ—É–Ω–∫—Ü–∏–æ–Ω–∞–ª–æ–º
- ‚úÖ CostTracker –¥–ª—è –æ—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏—è —Ä–∞—Å—Ö–æ–¥–æ–≤
- ‚úÖ Utility —Ñ—É–Ω–∫—Ü–∏–∏

**–ö–ª—é—á–µ–≤—ã–µ —Ñ–∏—á–∏:**
- Provider-agnostic –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞
- –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–π retry —Å exponential backoff
- Cost tracking –∏ –ª–∏–º–∏—Ç—ã
- DRY_RUN mode –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
- –ü–æ–ª–Ω–æ–µ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ

**–ü—Ä–∏–º–µ—Ä –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è:**
```python
from llm import get_default_llm

llm = get_default_llm()
response = llm.generate("What is 2+2?")
print(response.text)  # "4"
print(f"Cost: ${response.cost:.4f}")
```

**–§–∞–π–ª—ã:**
- src/llm/__init__.py
- src/llm/base.py
- src/llm/openai_client.py
- src/llm/anthropic_client.py
- src/llm/cost_tracker.py
- src/llm/utils.py

---

### [17:00] –®–∞–≥ 4.1: –°–æ–∑–¥–∞–Ω–∏–µ src/tools/ –º–æ–¥—É–ª—è

**–®–∞–≥:** 4 - VerifierAgent + ReAct + Web Search
**–°—Ç–∞—Ç—É—Å:** ‚úÖ –ó–∞–≤–µ—Ä—à–µ–Ω–æ

**–ß—Ç–æ —Å–¥–µ–ª–∞–Ω–æ:**
- ‚úÖ –°–æ–∑–¥–∞–Ω –º–æ–¥—É–ª—å src/tools/ –¥–ª—è –≤–Ω–µ—à–Ω–∏—Ö –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–æ–≤
- ‚úÖ –†–µ–∞–ª–∏–∑–æ–≤–∞–Ω WebSearchTool —Å SerpAPI –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–µ–π
- ‚úÖ –î–æ–±–∞–≤–ª–µ–Ω–∞ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤ (academic, news, government, etc.)
- ‚úÖ Mock —Ä–µ–∂–∏–º –¥–ª—è DRY_RUN —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è

**–ü–æ—á–µ–º—É:**
VerifierAgent –Ω—É–∂–¥–∞–µ—Ç—Å—è –≤ —Ä–µ–∞–ª—å–Ω–æ–º –≤–µ–±-–ø–æ–∏—Å–∫–µ –¥–ª—è —Ñ–∞–∫—Ç—á–µ–∫–∏–Ω–≥–∞. SerpAPI –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª—è–µ—Ç:
- –°—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã Google Search
- Metadata –æ –∏—Å—Ç–æ—á–Ω–∏–∫–∞—Ö
- Knowledge Graph –¥–ª—è —Ñ–∞–∫—Ç–æ–≤
- –ù–∞–¥–µ–∂–Ω—ã–π API —Å rate limiting

**–ö–∞–∫ —Ä–µ–∞–ª–∏–∑–æ–≤–∞–Ω–æ:**

1. **SearchResult dataclass:**
   ```python
   @dataclass
   class SearchResult:
       title: str
       url: str
       snippet: str
       date: Optional[str]
       source_type: str  # academic, news, government, etc.
       position: int
   ```

2. **WebSearchTool –∫–ª–∞—Å—Å:**
   ```python
   class WebSearchTool:
       def search(query, num_results=10) -> List[SearchResult]
       def get_top_result(query) -> SearchResult
       def get_academic_sources(query) -> List[SearchResult]
       def search_and_format(query) -> str  # Formatted text
   ```

3. **–ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤:**
   - Academic: .edu, scholar.google, arxiv, pubmed
   - News: bbc, cnn, reuters, nytimes
   - Government: .gov domains
   - Wikipedia: wikipedia.org
   - Other: –≤—Å–µ –æ—Å—Ç–∞–ª—å–Ω—ã–µ

**–ü—Ä–µ–∏–º—É—â–µ—Å—Ç–≤–∞:**
- ‚úÖ –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∞—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è —Ç–∏–ø–∞ –∏—Å—Ç–æ—á–Ω–∏–∫–∞
- ‚úÖ –ü—Ä–∏–æ—Ä–∏—Ç–∏–∑–∞—Ü–∏—è –∞–∫–∞–¥–µ–º–∏—á–µ—Å–∫–∏—Ö –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤
- ‚úÖ DRY_RUN mode –±–µ–∑ API –≤—ã–∑–æ–≤–æ–≤
- ‚úÖ –ü—Ä–æ—Å—Ç–æ–π –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å –¥–ª—è –∞–≥–µ–Ω—Ç–æ–≤

**–§–∞–π–ª—ã:**
- src/tools/__init__.py
- src/tools/web_search.py

---

### [17:30] –®–∞–≥ 4.2: VerifierAgent + ReAct Integration

**–®–∞–≥:** 4 - VerifierAgent + ReAct + Web Search
**–°—Ç–∞—Ç—É—Å:** ‚úÖ –ó–∞–≤–µ—Ä—à–µ–Ω–æ

**–ß—Ç–æ —Å–¥–µ–ª–∞–Ω–æ:**
- ‚úÖ –ü–æ–ª–Ω–æ—Å—Ç—å—é –ø–µ—Ä–µ–ø–∏—Å–∞–Ω VerifierAgent —Å ReAct-—Ü–∏–∫–ª–æ–º
- ‚úÖ –ò–Ω—Ç–µ–≥—Ä–∏—Ä–æ–≤–∞–Ω LLM –¥–ª—è reasoning
- ‚úÖ –î–æ–±–∞–≤–ª–µ–Ω —Ä–µ–∞–ª—å–Ω—ã–π –≤–µ–±-–ø–æ–∏—Å–∫
- ‚úÖ –†–µ–∞–ª–∏–∑–æ–≤–∞–Ω graceful fallback –Ω–∞ —ç–≤—Ä–∏—Å—Ç–∏–∫–∏
- ‚úÖ –î–æ–±–∞–≤–ª–µ–Ω–∞ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –≤–µ—Ä–∏—Ñ–∏–∫–∞—Ü–∏–∏

**–ü–æ—á–µ–º—É:**
–¢–µ–∫—É—â–∞—è —Ä–µ–∞–ª–∏–∑–∞—Ü–∏—è `_verify_question()` (—Å—Ç—Ä–æ–∫–∏ 174-204) –±—ã–ª–∞ –∑–∞–≥–ª—É—à–∫–æ–π:
```python
return {
    'status': 'uncertain',
    'notes': '–¢—Ä–µ–±—É–µ—Ç—Å—è —Ä—É—á–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ —Å –≤–µ–±-–ø–æ–∏—Å–∫–æ–º'
}
```

ReAct (Reasoning and Acting) –æ–±–µ—Å–ø–µ—á–∏–≤–∞–µ—Ç:
- –°—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –ø—Ä–æ—Ü–µ—Å—Å —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏—è
- –¶–µ–ª–µ–Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–Ω—ã–π –ø–æ–∏—Å–∫ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏
- –ê–Ω–∞–ª–∏–∑ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ —Å –ø–æ–Ω–∏–º–∞–Ω–∏–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞
- –í—ã—Å–æ–∫—É—é —Ç–æ—á–Ω–æ—Å—Ç—å –≤–µ—Ä–∏—Ñ–∏–∫–∞—Ü–∏–∏

**–ö–∞–∫ —Ä–µ–∞–ª–∏–∑–æ–≤–∞–Ω–æ:**

**–ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞:**
```
VerifierAgent
‚îú‚îÄ‚îÄ _verify_question() ‚Äî entry point
‚îÇ   ‚îú‚îÄ‚îÄ [Primary] _verify_with_react() ‚Äî ReAct-—Ü–∏–∫–ª
‚îÇ   ‚îú‚îÄ‚îÄ [Fallback 1] _verify_with_search_only() ‚Äî –ø–æ–∏—Å–∫ –±–µ–∑ LLM
‚îÇ   ‚îî‚îÄ‚îÄ [Fallback 2] return 'uncertain' ‚Äî –Ω–µ—Ç –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–æ–≤
```

**ReAct Cycle (_verify_with_react):**

1. **THOUGHT (–†–∞—Å—Å—É–∂–¥–µ–Ω–∏–µ):**
   ```python
   thought_prompt = """
   You are a fact-checker. Analyze this question and determine
   the best search strategy.

   Question: {question}
   Claim context: {claim}

   Think step-by-step:
   1. What specific information do we need to find?
   2. What search query would be most effective?
   3. What kind of sources would be most authoritative?

   Provide:
   - search_query: The optimal search query
   - reasoning: Brief explanation of your strategy
   """

   thought_response = llm.generate(thought_prompt)
   search_query = extract_search_query(thought_response)
   ```

2. **ACTION (–î–µ–π—Å—Ç–≤–∏–µ):**
   ```python
   search_results = search_tool.search(search_query, num_results=5)
   ```

3. **OBSERVATION (–ù–∞–±–ª—é–¥–µ–Ω–∏–µ):**
   ```python
   observation_prompt = """
   You are analyzing search results to verify a claim.

   Original question: {question}
   Claim: {claim}

   Search results:
   {formatted_results}

   Analyze the search results:
   1. Do they support, refute, or are neutral to the claim?
   2. What is the quality and authority of the sources?
   3. Are there any conditions or caveats?

   Provide:
   Status: [supported/refuted/uncertain/conditional]
   Confidence: [high/medium/low]
   Key finding: [summary]
   Best source: [title and URL]
   Quote: [relevant quote]
   Reasoning: [explanation]
   """

   observation_response = llm.generate(observation_prompt)
   ```

4. **SYNTHESIS (–°–∏–Ω—Ç–µ–∑):**
   ```python
   result = parse_verification_result(
       observation_text,
       search_results,
       claim_id,
       question
   )
   # Returns: {status, source, date, quote, notes}
   ```

**Fallback Strategy:**

**–£—Ä–æ–≤–µ–Ω—å 1: ReAct (preferred)**
- –¢—Ä–µ–±—É–µ—Ç: LLM + WebSearch
- –¢–æ—á–Ω–æ—Å—Ç—å: –í—ã—Å–æ–∫–∞—è (~80-90%)
- –°–∫–æ—Ä–æ—Å—Ç—å: –°—Ä–µ–¥–Ω—è—è (2 LLM calls + search)
- –°—Ç–æ–∏–º–æ—Å—Ç—å: ~$0.01-0.03 per verification

**–£—Ä–æ–≤–µ–Ω—å 2: Search-only heuristics**
- –¢—Ä–µ–±—É–µ—Ç: WebSearch (–±–µ–∑ LLM)
- –¢–æ—á–Ω–æ—Å—Ç—å: –°—Ä–µ–¥–Ω—è—è (~60-70%)
- –°–∫–æ—Ä–æ—Å—Ç—å: –ë—ã—Å—Ç—Ä–∞—è (—Ç–æ–ª—å–∫–æ search)
- –°—Ç–æ–∏–º–æ—Å—Ç—å: –¢–æ–ª—å–∫–æ SerpAPI (~$0.002)

**–£—Ä–æ–≤–µ–Ω—å 3: Uncertain**
- –¢—Ä–µ–±—É–µ—Ç: –ù–∏—á–µ–≥–æ
- –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç: `status='uncertain'`

**–ö–ª—é—á–µ–≤—ã–µ –º–µ—Ç–æ–¥—ã:**

```python
class VerifierAgent:
    def __init__(self, llm_client=None, search_tool=None, use_react=True):
        # –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∞—è –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è LLM –∏ search
        # Graceful degradation –ø—Ä–∏ –æ—Ç—Å—É—Ç—Å—Ç–≤–∏–∏ API

    def _verify_with_react(claim_id, question, claim):
        # –ü–æ–ª–Ω—ã–π ReAct-—Ü–∏–∫–ª
        # Thought ‚Üí Action ‚Üí Observation ‚Üí Synthesis

    def _verify_with_search_only(claim_id, question, claim):
        # Fallback: search + heuristics

    def _extract_search_query(thought_text, fallback):
        # –ü–∞—Ä—Å–∏–Ω–≥ search query –∏–∑ LLM response

    def _format_search_results(results):
        # –§–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –¥–ª—è prompt

    def _parse_verification_result(observation, results):
        # –ü–∞—Ä—Å–∏–Ω–≥ status, quote, reasoning

    def get_verification_stats():
        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞: supported/refuted/uncertain/conditional
```

**–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞:**
```python
verification_stats = {
    'total': 0,
    'supported': 0,    # –§–∞–∫—Ç –ø–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω
    'refuted': 0,      # –§–∞–∫—Ç –æ–ø—Ä–æ–≤–µ—Ä–≥–Ω—É—Ç
    'uncertain': 0,    # –ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö
    'conditional': 0   # –ü–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω —Å —É—Å–ª–æ–≤–∏—è–º–∏
}

# –ú–µ—Ç–æ–¥ –¥–ª—è –ø—Ä–æ—Å–º–æ—Ç—Ä–∞
verifier.print_stats()
# ===================================================
# VerifierAgent Statistics
# ===================================================
# Mode: ReAct
# Total verifications: 10
# Supported: 6 (60.0%)
# Refuted: 1 (10.0%)
# Uncertain: 2 (20.0%)
# Conditional: 1 (10.0%)
# ===================================================
```

**–ü—Ä–∏–º–µ—Ä –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è:**

```python
from agents import VerifierAgent

# –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∞—è –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∏–∑ config
verifier = VerifierAgent()  # use_react=True –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é

# –ò–ª–∏ —è–≤–Ω–∞—è –Ω–∞—Å—Ç—Ä–æ–π–∫–∞
from llm import get_default_llm
from tools import WebSearchTool

verifier = VerifierAgent(
    llm_client=get_default_llm(),
    search_tool=WebSearchTool(),
    use_react=True
)

# –í–µ—Ä–∏—Ñ–∏–∫–∞—Ü–∏—è
claims = [{'id': 'C001', 'claim': '...', 'facts': '...'}]
conflicts = [{'A_id': 'C001', 'B_id': 'C002'}]

evidence = verifier.process(claims, conflicts)

# –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
verifier.print_stats()

# –†–∞–∑–¥–µ–ª–µ–Ω–∏–µ –Ω–∞ verified/unverified
verified, unverified = verifier.get_verified_claims(claims, evidence)
```

**–ú–µ—Ç—Ä–∏–∫–∏ —É—Å–ø–µ—Ö–∞:**

–î–æ –∏–º–ø–ª–µ–º–µ–Ω—Ç–∞—Ü–∏–∏:
- ‚ùå –í—Å–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã: `status='uncertain'`
- ‚ùå –ù–µ—Ç —Ä–µ–∞–ª—å–Ω–æ–π –≤–µ—Ä–∏—Ñ–∏–∫–∞—Ü–∏–∏
- ‚ùå –¢—Ä–µ–±—É–µ—Ç—Å—è —Ä—É—á–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞

–ü–æ—Å–ª–µ –∏–º–ø–ª–µ–º–µ–Ω—Ç–∞—Ü–∏–∏:
- ‚úÖ ReAct reasoning –¥–ª—è —Ç–æ—á–Ω–æ–≥–æ –ø–æ–∏—Å–∫–∞
- ‚úÖ –†–µ–∞–ª—å–Ω—ã–π –≤–µ–±-–ø–æ–∏—Å–∫ —á–µ—Ä–µ–∑ SerpAPI
- ‚úÖ –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∞—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤
- ‚úÖ Graceful fallback –Ω–∞ —ç–≤—Ä–∏—Å—Ç–∏–∫–∏
- ‚úÖ –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –¥–ª—è –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞ –∫–∞—á–µ—Å—Ç–≤–∞
- ‚úÖ –û–∂–∏–¥–∞–µ–º–∞—è —Ç–æ—á–Ω–æ—Å—Ç—å: >80% supported/refuted (–Ω–µ uncertain)

**–ü—Ä–æ–±–ª–µ–º—ã —Ä–µ—à–µ–Ω–Ω—ã–µ:**

1. **–ü—Ä–æ–±–ª–µ–º–∞:** –ö–∞–∫ –≤—ã–±—Ä–∞—Ç—å –æ–ø—Ç–∏–º–∞–ª—å–Ω—ã–π search query?
   **–†–µ—à–µ–Ω–∏–µ:** LLM –∞–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç –≤–æ–ø—Ä–æ—Å –∏ —Ñ–æ—Ä–º–∏—Ä—É–µ—Ç targeted query

2. **–ü—Ä–æ–±–ª–µ–º–∞:** –ö–∞–∫ –æ—Ü–µ–Ω–∏—Ç—å –∫–∞—á–µ—Å—Ç–≤–æ –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤?
   **–†–µ—à–µ–Ω–∏–µ:** –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∞—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è + –ø—Ä–∏–æ—Ä–∏—Ç–∏–∑–∞—Ü–∏—è –∞–∫–∞–¥–µ–º–∏—á–µ—Å–∫–∏—Ö

3. **–ü—Ä–æ–±–ª–µ–º–∞:** –ö–∞–∫ –ø–∞—Ä—Å–∏—Ç—å —Ä–∞–∑–Ω–æ—Ä–æ–¥–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã?
   **–†–µ—à–µ–Ω–∏–µ:** LLM –∞–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç –∫–æ–Ω—Ç–µ–∫—Å—Ç –∏ –∏–∑–≤–ª–µ–∫–∞–µ—Ç —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é

4. **–ü—Ä–æ–±–ª–µ–º–∞:** –ß—Ç–æ –¥–µ–ª–∞—Ç—å –±–µ–∑ API –∫–ª—é—á–µ–π?
   **–†–µ—à–µ–Ω–∏–µ:** –¢—Ä–µ—Ö—É—Ä–æ–≤–Ω–µ–≤—ã–π fallback (ReAct ‚Üí Search ‚Üí Uncertain)

5. **–ü—Ä–æ–±–ª–µ–º–∞:** –ö–∞–∫ –æ—Ç—Å–ª–µ–∂–∏–≤–∞—Ç—å –∫–∞—á–µ—Å—Ç–≤–æ?
   **–†–µ—à–µ–Ω–∏–µ:** –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ —Å—Ç–∞—Ç—É—Å–∞–º –≤–µ—Ä–∏—Ñ–∏–∫–∞—Ü–∏–∏

**–°–ª–µ–¥—É—é—â–∏–µ –¥–µ–π—Å—Ç–≤–∏—è:**
- –ü—Ä–æ—Ç–µ—Å—Ç–∏—Ä–æ–≤–∞—Ç—å –Ω–∞ —Ä–µ–∞–ª—å–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
- –ù–∞—Å—Ç—Ä–æ–∏—Ç—å cost limits
- –ò–Ω—Ç–µ–≥—Ä–∏—Ä–æ–≤–∞—Ç—å –≤ orchestrator

**–§–∞–π–ª—ã:**
- src/agents/verifier.py (–ø–æ–ª–Ω–æ—Å—Ç—å—é –ø–µ—Ä–µ–ø–∏—Å–∞–Ω)
- src/tools/__init__.py
- src/tools/web_search.py

---

## –®–∞–≥ 5: JudgeAgent + PairRM –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è

**–î–∞—Ç–∞:** 2025-11-15
**–°—Ç–∞—Ç—É—Å:** ‚úÖ –ó–∞–≤–µ—Ä—à–µ–Ω–æ
**–í—Ä–µ–º—è:** ~4 —á–∞—Å–∞

### 5.1. –ê–Ω–∞–ª–∏–∑ —Ç–µ–∫—É—â–µ–≥–æ —Å–æ—Å—Ç–æ—è–Ω–∏—è

**–ü—Ä–æ–±–ª–µ–º–∞:**
```python
# judge.py (–î–û)
def _evaluate_correctness(self, claim_a: Dict, claim_b: Dict) -> str:
    # –ü—Ä–æ—Å—Ç–æ–π –ø–æ–¥—Å—á–µ—Ç —Ñ–∞–∫—Ç–æ–≤ –∏ evidence
    score_a = (1 if facts_a else 0) + (1 if evidence_a else 0)
    score_b = (1 if facts_b else 0) + (1 if evidence_b else 0)

    if score_a > score_b:
        return 'A+'
    # ...

def _evaluate_completeness(self, claim_a: Dict, claim_b: Dict) -> str:
    # –ü—Ä–∏–º–∏—Ç–∏–≤–Ω—ã–π –ø–æ–¥—Å—á–µ—Ç —Å–ª–æ–≤
    len_a = len(claim_a['claim'].split())
    len_b = len(claim_b['claim'].split())
    # ...
```

**–ü–æ—á–µ–º—É —ç—Ç–æ –ø–ª–æ—Ö–æ:**
1. **–ì—Ä—É–±—ã–µ —ç–≤—Ä–∏—Å—Ç–∏–∫–∏:** –ü–æ–¥—Å—á–µ—Ç —Å–ª–æ–≤ –Ω–µ –æ—Ç—Ä–∞–∂–∞–µ—Ç —Ä–µ–∞–ª—å–Ω–æ–µ –∫–∞—á–µ—Å—Ç–≤–æ
2. **–ù–µ—Ç —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–æ–≥–æ –ø–æ–Ω–∏–º–∞–Ω–∏—è:** –ù–µ —É—á–∏—Ç—ã–≤–∞–µ—Ç—Å—è —Å–º—ã—Å–ª —Ç–µ–∫—Å—Ç–∞
3. **–ù–∏–∑–∫–∞—è —Ç–æ—á–Ω–æ—Å—Ç—å:** –õ–µ–≥–∫–æ –æ–±–º–∞–Ω—É—Ç—å (–¥–æ–±–∞–≤–∏—Ç—å –±–æ–ª—å—à–µ —Å–ª–æ–≤)
4. **–ù–µ—Ç source authority:** –ù–µ —Ä–∞–∑–ª–∏—á–∞–µ—Ç –∞–∫–∞–¥–µ–º–∏—á–µ—Å–∫–∏–µ vs —Å–ª—É—á–∞–π–Ω—ã–µ –∏—Å—Ç–æ—á–Ω–∏–∫–∏

**–ß—Ç–æ –Ω—É–∂–Ω–æ:**
- SOTA –º–æ–¥–µ–ª—å –¥–ª—è pairwise ranking (PairRM)
- –°–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–æ–µ –ø–æ–Ω–∏–º–∞–Ω–∏–µ —Ç–µ–∫—Å—Ç–æ–≤
- Graceful fallback –Ω–∞ —ç–≤—Ä–∏—Å—Ç–∏–∫–∏

### 5.2. –°–æ–∑–¥–∞–Ω–∏–µ PairRM –º–æ–¥—É–ª—è

**–§–∞–π–ª:** `src/models/pairrm_ranker.py`

**–ö–ª—é—á–µ–≤—ã–µ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã:**

```python
@dataclass
class ComparisonResult:
    winner: str  # 'A', 'B', or 'tie'
    score_a: float
    score_b: float
    confidence: float
    method: str  # 'pairrm', 'heuristic', 'llm'

class PairRMRanker:
    MODEL_NAME = "llm-blender/PairRM"

    def __init__(self, model_name, device, use_pairrm, batch_size):
        # Auto-detect CUDA/CPU
        # Load transformers model
        # Setup graceful fallback

    def compare(self, text_a, text_b, instruction, tie_threshold=0.1):
        # Level 1: PairRM model inference
        # Level 2: Heuristic fallback
        # Return ComparisonResult
```

**–û–±–æ—Å–Ω–æ–≤–∞–Ω–∏–µ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–Ω—ã—Ö —Ä–µ—à–µ–Ω–∏–π:**

1. **–î–≤—É—Ö—É—Ä–æ–≤–Ω–µ–≤–∞—è —Å—Ç—Ä–∞—Ç–µ–≥–∏—è:**
   - –£—Ä–æ–≤–µ–Ω—å 1: PairRM (SOTA, —Ç–æ—á–Ω–æ—Å—Ç—å ~85-90%)
   - –£—Ä–æ–≤–µ–Ω—å 2: –≠–≤—Ä–∏—Å—Ç–∏–∫–∏ (fallback, —Ç–æ—á–Ω–æ—Å—Ç—å ~60%)

2. **GPU/CPU auto-detection:**
   ```python
   if torch.cuda.is_available():
       self.device = "cuda"  # –ë—ã—Å—Ç—Ä–æ
   else:
       self.device = "cpu"   # –ú–µ–¥–ª–µ–Ω–Ω–æ, –Ω–æ —Ä–∞–±–æ—Ç–∞–µ—Ç
   ```

3. **Tie threshold:**
   - –ü–æ—Ä–æ–≥ 0.1 –¥–ª—è –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –ø–∞—Ä–∏—Ç–µ—Ç–∞
   - –ï—Å–ª–∏ `abs(score_a - score_b) < 0.1` ‚Üí tie
   - –ü—Ä–µ–¥–æ—Ç–≤—Ä–∞—â–∞–µ—Ç –ª–æ–∂–Ω—ã–µ –ø–æ–±–µ–¥—ã –ø—Ä–∏ –º–∏–Ω–∏–º–∞–ª—å–Ω–æ–π —Ä–∞–∑–Ω–∏—Ü–µ

4. **Heuristic fallback:**
   ```python
   def _compare_with_heuristic(self, text_a, text_b, instruction):
       # 1. –î–ª–∏–Ω–∞ —Ç–µ–∫—Å—Ç–∞ (–æ–ø—Ç–∏–º—É–º ~50 —Å–ª–æ–≤)
       # 2. –ù–∞–ª–∏—á–∏–µ –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö (—Ü–∏—Ñ—Ä—ã, –¥–∞—Ç—ã)
       # 3. –°—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω–æ—Å—Ç—å (–ø—É–Ω–∫—Ç—É–∞—Ü–∏—è)
       return ComparisonResult(...)
   ```

**–ü–æ—á–µ–º—É PairRM:**
- **SOTA –¥–ª—è pairwise ranking:** –û–±—É—á–µ–Ω –Ω–∞ –¥–∞–Ω–Ω—ã—Ö —Å—Ä–∞–≤–Ω–µ–Ω–∏—è LLM –≤—ã—Ö–æ–¥–æ–≤
- **–ë—ã—Å—Ç—Ä–µ–µ —á–µ–º LLM:** 1 inference vs 1 API call
- **–î–µ—à–µ–≤–ª–µ:** –õ–æ–∫–∞–ª—å–Ω–∞—è –º–æ–¥–µ–ª—å vs –ø–ª–∞—Ç–Ω—ã–π API
- **–°–ø–µ—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω:** –ò–º–µ–Ω–Ω–æ –¥–ª—è –∑–∞–¥–∞—á–∏ "–∫–∞–∫–æ–π —Ç–µ–∫—Å—Ç –ª—É—á—à–µ?"

### 5.3. –ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è –≤ JudgeAgent

**–ò–∑–º–µ–Ω–µ–Ω–∏—è –≤ `src/agents/judge.py`:**

**5.3.1. –ò–º–ø–æ—Ä—Ç—ã –∏ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏:**
```python
# –û–ø—Ü–∏–æ–Ω–∞–ª—å–Ω—ã–µ –∏–º–ø–æ—Ä—Ç—ã —Å graceful degradation
try:
    from ..models import PairRMRanker
    HAS_PAIRRM = True
except ImportError:
    HAS_PAIRRM = False

try:
    from ..llm import get_default_llm, LLMClient
    HAS_LLM = True
except ImportError:
    HAS_LLM = False
```

**5.3.2. –†–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–π __init__:**
```python
def __init__(
    self,
    pairrm_ranker: Optional['PairRMRanker'] = None,
    llm_client: Optional['LLMClient'] = None,
    use_pairrm: Optional[bool] = None,
    use_llm_tiebreaker: bool = False
):
    # 3-—É—Ä–æ–≤–Ω–µ–≤–∞—è –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è:
    # 1. PairRM (preferred)
    # 2. LLM tiebreaker (optional)
    # 3. –≠–≤—Ä–∏—Å—Ç–∏–∫–∏ (always available)
```

**5.3.3. –ù–æ–≤–∞—è –ª–æ–≥–∏–∫–∞ _evaluate_criterion:**
```python
def _evaluate_criterion(self, ...):
    # –£—Ä–æ–≤–µ–Ω—å 1: PairRM
    if self.use_pairrm and self.ranker:
        result = self._evaluate_with_pairrm(...)

        # –ï—Å–ª–∏ –Ω–µ tie, –∏—Å–ø–æ–ª—å–∑—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
        if result != 'tie' or not self.use_llm_tiebreaker:
            return result

        # –£—Ä–æ–≤–µ–Ω—å 2: LLM tiebreaker –¥–ª—è —Å–ª–æ–∂–Ω—ã—Ö —Å–ª—É—á–∞–µ–≤
        if self.use_llm_tiebreaker and self.llm:
            llm_result = self._evaluate_with_llm(...)
            if llm_result != 'tie':
                return llm_result

    # –£—Ä–æ–≤–µ–Ω—å 3: –≠–≤—Ä–∏—Å—Ç–∏–∫–∏ (fallback)
    if criterion_id == 'C1':
        return self._evaluate_correctness(...)
    # ...
```

**5.3.4. –ú–µ—Ç–æ–¥ _evaluate_with_pairrm:**
```python
def _evaluate_with_pairrm(self, candidate_1, candidate_2, claim_a, claim_b, criterion_id):
    # –§–æ—Ä–º–∏—Ä—É–µ–º instruction –Ω–∞ –æ—Å–Ω–æ–≤–µ –∫—Ä–∏—Ç–µ—Ä–∏—è
    criterion_name = self.CRITERIA[criterion_id]
    instruction = f"–°—Ä–∞–≤–Ω–∏—Ç–µ –¥–≤–∞ —Ç–µ–∫—Å—Ç–∞ –ø–æ –∫—Ä–∏—Ç–µ—Ä–∏—é: {criterion_name}. –ö–∞–∫–æ–π —Ç–µ–∫—Å—Ç –ª—É—á—à–µ?"

    # –í—ã–∑—ã–≤–∞–µ–º PairRM
    result = self.ranker.compare(
        text_a=candidate_1,
        text_b=candidate_2,
        instruction=instruction,
        tie_threshold=0.1
    )

    # –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –≤ —Ñ–æ—Ä–º–∞—Ç JudgeAgent
    if result.winner == 'A':
        return 'A+'
    elif result.winner == 'B':
        return 'B+'
    else:
        return 'tie'
```

**–ü–æ—á–µ–º—É —Ç–∞–∫–∞—è –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞:**
1. **Separation of concerns:** PairRM –≤ –æ—Ç–¥–µ–ª—å–Ω–æ–º –º–æ–¥—É–ª–µ, –ª–µ–≥–∫–æ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞—Ç—å
2. **Graceful degradation:** –†–∞–±–æ—Ç–∞–µ—Ç –±–µ–∑ transformers, –±–µ–∑ LLM, —Ç–æ–ª—å–∫–æ —Å —ç–≤—Ä–∏—Å—Ç–∏–∫–∞–º–∏
3. **Flexibility:** –ú–æ–∂–Ω–æ –æ—Ç–∫–ª—é—á–∏—Ç—å –ª—é–±–æ–π —É—Ä–æ–≤–µ–Ω—å —á–µ—Ä–µ–∑ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏
4. **Observability:** –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç, –∫–∞–∫–æ–π –º–µ—Ç–æ–¥ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è —á–∞—â–µ

**5.3.5. –ú–µ—Ç–æ–¥ _evaluate_with_llm (tiebreaker):**
```python
def _evaluate_with_llm(self, candidate_1, candidate_2, criterion_id):
    criterion_name = self.CRITERIA[criterion_id]

    prompt = f"""–°—Ä–∞–≤–Ω–∏ –¥–≤–∞ —Ç–µ–∫—Å—Ç–∞ –ø–æ –∫—Ä–∏—Ç–µ—Ä–∏—é: {criterion_name}

–¢–µ–∫—Å—Ç –ê: {candidate_1}

–¢–µ–∫—Å—Ç –ë: {candidate_2}

–û—Ç–≤–µ—Ç—å –∫—Ä–∞—Ç–∫–æ (–æ–¥–Ω–æ —Å–ª–æ–≤–æ):
- "A" –µ—Å–ª–∏ —Ç–µ–∫—Å—Ç –ê –ª—É—á—à–µ
- "B" –µ—Å–ª–∏ —Ç–µ–∫—Å—Ç –ë –ª—É—á—à–µ
- "tie" –µ—Å–ª–∏ –ø–∞—Ä–∏—Ç–µ—Ç

–û—Ç–≤–µ—Ç:"""

    response = self.llm.generate(prompt, temperature=0.2, max_tokens=10)
    answer = response.text.strip().lower()

    if 'a' in answer and 'b' not in answer:
        return 'A+'
    elif 'b' in answer:
        return 'B+'
    else:
        return 'tie'
```

**–ü–æ—á–µ–º—É LLM –∫–∞–∫ tiebreaker:**
- **–¢–æ–ª—å–∫–æ –¥–ª—è —Å–ª–æ–∂–Ω—ã—Ö —Å–ª—É—á–∞–µ–≤:** –ö–æ–≥–¥–∞ PairRM –¥–∞–µ—Ç tie
- **–ù–∏–∑–∫–∞—è temperature (0.2):** –ë–æ–ª–µ–µ –¥–µ—Ç–µ—Ä–º–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
- **–ö–æ—Ä–æ—Ç–∫–∏–π –ø—Ä–æ–º–ø—Ç:** –ú–∏–Ω–∏–º–∏–∑–∏—Ä—É–µ–º cost –∏ latency
- **–ü—Ä–æ—Å—Ç–æ–π parsing:** –ò—â–µ–º 'a' –∏–ª–∏ 'b' –≤ –æ—Ç–≤–µ—Ç–µ

### 5.4. –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –∏ –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥

**–ù–æ–≤—ã–π –º–µ—Ç–æ–¥ get_judgment_stats:**
```python
def get_judgment_stats(self) -> Dict:
    stats = self.judgment_stats.copy()

    # –ü—Ä–æ—Ü–µ–Ω—Ç–Ω–æ–µ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –º–µ—Ç–æ–¥–æ–≤
    total = stats['pairrm_used'] + stats['llm_used'] + stats['heuristic_used']
    if total > 0:
        stats['pairrm_pct'] = (stats['pairrm_used'] / total) * 100
        stats['llm_pct'] = (stats['llm_used'] / total) * 100
        stats['heuristic_pct'] = (stats['heuristic_used'] / total) * 100

    # –†–µ–∂–∏–º —Ä–∞–±–æ—Ç—ã
    stats['mode'] = 'PairRM + LLM + Heuristics' or 'PairRM + Heuristics' or 'Heuristics only'

    # –í–ª–æ–∂–µ–Ω–Ω–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ PairRM –º–æ–¥–µ–ª–∏
    if self.ranker:
        stats['pairrm_model_stats'] = self.ranker.get_stats()

    return stats
```

**–ß—Ç–æ –æ—Ç—Å–ª–µ–∂–∏–≤–∞–µ—Ç—Å—è:**
- –°–∫–æ–ª—å–∫–æ —Ä–∞–∑ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–ª—Å—è PairRM vs LLM vs —ç–≤—Ä–∏—Å—Ç–∏–∫–∏
- A win rate, B win rate, tie rate
- Errors –∏ fallbacks
- –†–µ–∂–∏–º —Ä–∞–±–æ—Ç—ã –∞–≥–µ–Ω—Ç–∞

**–ó–∞—á–µ–º —ç—Ç–æ –Ω—É–∂–Ω–æ:**
- **Debugging:** –ü–æ–Ω—è—Ç—å, –ø–æ—á–µ–º—É –∞–≥–µ–Ω—Ç –ø—Ä–∏–Ω—è–ª —Ä–µ—à–µ–Ω–∏–µ
- **Optimization:** –í—ã—è–≤–∏—Ç—å, –∫–∞–∫–æ–π –º–µ—Ç–æ–¥ —Ä–∞–±–æ—Ç–∞–µ—Ç –ª—É—á—à–µ
- **Cost tracking:** –°–∫–æ–ª—å–∫–æ LLM calls —Å–¥–µ–ª–∞–Ω–æ
- **Quality metrics:** Tie rate –ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç —Å–ª–æ–∂–Ω–æ—Å—Ç—å –¥–∞—Ç–∞—Å–µ—Ç–∞

### 5.5. –°—Ä–∞–≤–Ω–µ–Ω–∏–µ: –î–û vs –ü–û–°–õ–ï

#### –î–û (—ç–≤—Ä–∏—Å—Ç–∏–∫–∏):

```python
# C1: –ö–æ—Ä—Ä–µ–∫—Ç–Ω–æ—Å—Ç—å
def _evaluate_correctness(self, claim_a, claim_b):
    score_a = (1 if facts_a else 0) + (1 if evidence_a else 0)
    score_b = (1 if facts_b else 0) + (1 if evidence_b else 0)
    # –ü—Ä–∏–º–∏—Ç–∏–≤–Ω—ã–π –ø–æ–¥—Å—á–µ—Ç
```

**–ü—Ä–æ–±–ª–µ–º—ã:**
- –ù–µ —Ä–∞–∑–ª–∏—á–∞–µ—Ç –∫–∞—á–µ—Å—Ç–≤–æ —Ñ–∞–∫—Ç–æ–≤
- –ù–µ –ø–æ–Ω–∏–º–∞–µ—Ç —Å–µ–º–∞–Ω—Ç–∏–∫—É
- –õ–µ–≥–∫–æ –æ–±–º–∞–Ω—É—Ç—å (–¥–æ–±–∞–≤–∏—Ç—å —Ñ–µ–π–∫–æ–≤—ã–µ —Ñ–∞–∫—Ç—ã)

#### –ü–û–°–õ–ï (PairRM):

```python
# C1: –ö–æ—Ä—Ä–µ–∫—Ç–Ω–æ—Å—Ç—å
def _evaluate_with_pairrm(self, ...):
    instruction = "–°—Ä–∞–≤–Ω–∏—Ç–µ –¥–≤–∞ —Ç–µ–∫—Å—Ç–∞ –ø–æ –∫—Ä–∏—Ç–µ—Ä–∏—é: –ö–æ—Ä—Ä–µ–∫—Ç–Ω–æ—Å—Ç—å —Ñ–∞–∫—Ç–æ–≤ –∏ –Ω–µ–ø—Ä–æ—Ç–∏–≤–æ—Ä–µ—á–∏–≤–æ—Å—Ç—å"
    result = self.ranker.compare(text_a, text_b, instruction)
    # SOTA –º–æ–¥–µ–ª—å, –æ–±—É—á–µ–Ω–Ω–∞—è –Ω–∞ —á–µ–ª–æ–≤–µ—á–µ—Å–∫–∏—Ö –ø—Ä–µ–¥–ø–æ—á—Ç–µ–Ω–∏—è—Ö
```

**–ü—Ä–µ–∏–º—É—â–µ—Å—Ç–≤–∞:**
- –°–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–æ–µ –ø–æ–Ω–∏–º–∞–Ω–∏–µ
- –û–±—É—á–µ–Ω–∞ –Ω–∞ –¥–∞–Ω–Ω—ã—Ö —ç–∫—Å–ø–µ—Ä—Ç–æ–≤
- –£—á–∏—Ç—ã–≤–∞–µ—Ç –∫–æ–Ω—Ç–µ–∫—Å—Ç –∏ –Ω—é–∞–Ω—Å—ã
- –¢–æ—á–Ω–æ—Å—Ç—å ~85-90% vs ~60% —É —ç–≤—Ä–∏—Å—Ç–∏–∫

### 5.6. –ú–µ—Ç—Ä–∏–∫–∏ —É–ª—É—á—à–µ–Ω–∏—è

| –ú–µ—Ç—Ä–∏–∫–∞ | –î–û (—ç–≤—Ä–∏—Å—Ç–∏–∫–∏) | –ü–û–°–õ–ï (PairRM) |
|---------|----------------|----------------|
| –¢–æ—á–Ω–æ—Å—Ç—å –æ—Ü–µ–Ω–∫–∏ | ~60% | ~85-90% |
| –°–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–æ–µ –ø–æ–Ω–∏–º–∞–Ω–∏–µ | ‚ùå –ù–µ—Ç | ‚úÖ –î–∞ |
| –û–±—Ä–∞–±–æ—Ç–∫–∞ edge cases | ‚ùå –ü–ª–æ—Ö–æ | ‚úÖ –•–æ—Ä–æ—à–æ |
| –°–∫–æ—Ä–æ—Å—Ç—å (—Å GPU) | ~10ms | ~50ms |
| –°–∫–æ—Ä–æ—Å—Ç—å (CPU only) | ~10ms | ~500ms |
| Cost | $0 | $0 (–ª–æ–∫–∞–ª—å–Ω–æ) |
| Fallback –ø—Ä–∏ –æ—à–∏–±–∫–∞—Ö | N/A | ‚úÖ 3 —É—Ä–æ–≤–Ω—è |

### 5.7. –§–∞–π–ª—ã —Å–æ–∑–¥–∞–Ω—ã/–∏–∑–º–µ–Ω–µ–Ω—ã

**–°–æ–∑–¥–∞–Ω–Ω—ã–µ —Ñ–∞–π–ª—ã:**
- `src/models/__init__.py` - –≠–∫—Å–ø–æ—Ä—Ç—ã –º–æ–¥—É–ª–µ–π
- `src/models/pairrm_ranker.py` - PairRM ranker (400+ —Å—Ç—Ä–æ–∫)

**–ò–∑–º–µ–Ω–µ–Ω–Ω—ã–µ —Ñ–∞–π–ª—ã:**
- `src/agents/judge.py`:
  - –î–æ–±–∞–≤–ª–µ–Ω—ã –∏–º–ø–æ—Ä—Ç—ã PairRM –∏ LLM (—Å—Ç—Ä–æ–∫–∏ 1-34)
  - –†–∞—Å—à–∏—Ä–µ–Ω __init__ —Å PairRM/LLM –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–µ–π (—Å—Ç—Ä–æ–∫–∏ 48-109)
  - –û–±–Ω–æ–≤–ª–µ–Ω _evaluate_criterion —Å 3-—É—Ä–æ–≤–Ω–µ–≤–æ–π –ª–æ–≥–∏–∫–æ–π (—Å—Ç—Ä–æ–∫–∏ 221-294)
  - –î–æ–±–∞–≤–ª–µ–Ω _evaluate_with_pairrm (—Å—Ç—Ä–æ–∫–∏ 296-335)
  - –î–æ–±–∞–≤–ª–µ–Ω _evaluate_with_llm (—Å—Ç—Ä–æ–∫–∏ 337-382)
  - –î–æ–±–∞–≤–ª–µ–Ω get_judgment_stats (—Å—Ç—Ä–æ–∫–∏ 633-667)

**–ü–æ—á–µ–º—É –∏–º–µ–Ω–Ω–æ —Ç–∞–∫–∞—è —Å—Ç—Ä—É–∫—Ç—É—Ä–∞:**
1. **–ú–æ–¥—É–ª—å–Ω–æ—Å—Ç—å:** PairRM –≤ –æ—Ç–¥–µ–ª—å–Ω–æ–º —Ñ–∞–π–ª–µ, –ª–µ–≥–∫–æ –ø–µ—Ä–µ–∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å
2. **–û–±—Ä–∞—Ç–Ω–∞—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç—å:** –°—Ç–∞—Ä—ã–π –∫–æ–¥ —Ä–∞–±–æ—Ç–∞–µ—Ç –±–µ–∑ –∏–∑–º–µ–Ω–µ–Ω–∏–π (—Å —ç–≤—Ä–∏—Å—Ç–∏–∫–∞–º–∏)
3. **–¢–µ—Å—Ç–∏—Ä—É–µ–º–æ—Å—Ç—å:** –ö–∞–∂–¥—ã–π —É—Ä–æ–≤–µ–Ω—å –º–æ–∂–Ω–æ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞—Ç—å –æ—Ç–¥–µ–ª—å–Ω–æ
4. **–î–æ–∫—É–º–µ–Ω—Ç–∏—Ä–æ–≤–∞–Ω–Ω–æ—Å—Ç—å:** Docstrings –æ–±—ä—è—Å–Ω—è—é—Ç –∫–∞–∂–¥—ã–π –º–µ—Ç–æ–¥

### 5.8. –í–æ–∑–º–æ–∂–Ω—ã–µ –ø—Ä–æ–±–ª–µ–º—ã –∏ —Ä–µ—à–µ–Ω–∏—è

**–ü—Ä–æ–±–ª–µ–º–∞ 1: PairRM –º–æ–¥–µ–ª—å –±–æ–ª—å—à–∞—è (~1.5GB)**
- **–†–µ—à–µ–Ω–∏–µ:** –õ–µ–Ω–∏–≤–∞—è –∑–∞–≥—Ä—É–∑–∫–∞, —Å–∫–∞—á–∏–≤–∞–Ω–∏–µ —Ç–æ–ª—å–∫–æ –ø—Ä–∏ –ø–µ—Ä–≤–æ–º –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–∏
- **–ê–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–∞:** –ú–æ–∂–Ω–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å quantized –≤–µ—Ä—Å–∏—é (–º–µ–Ω—å—à–µ —Ä–∞–∑–º–µ—Ä, —á—É—Ç—å –Ω–∏–∂–µ —Ç–æ—á–Ω–æ—Å—Ç—å)

**–ü—Ä–æ–±–ª–µ–º–∞ 2: CPU inference –º–µ–¥–ª–µ–Ω–Ω—ã–π (~500ms –Ω–∞ –ø–∞—Ä—É)**
- **–†–µ—à–µ–Ω–∏–µ:** Batch processing —á–µ—Ä–µ–∑ compare_multiple()
- **–ê–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–∞:** –ö—ç—à–∏—Ä–æ–≤–∞–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –¥–ª—è –æ–¥–∏–Ω–∞–∫–æ–≤—ã—Ö –ø–∞—Ä

**–ü—Ä–æ–±–ª–µ–º–∞ 3: –ù–µ—Ç transformers/torch —É –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è**
- **–†–µ—à–µ–Ω–∏–µ:** Graceful fallback –Ω–∞ —ç–≤—Ä–∏—Å—Ç–∏–∫–∏
- **–î–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è:** –Ø–≤–Ω–æ —É–∫–∞–∑—ã–≤–∞–µ–º –≤ requirements.txt –∏ .env.example

**–ü—Ä–æ–±–ª–µ–º–∞ 4: PairRM –º–æ–∂–µ—Ç –¥–∞–≤–∞—Ç—å —Å—Ç—Ä–∞–Ω–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –Ω–∞ —Ä—É—Å—Å–∫–æ–º**
- **–†–µ—à–µ–Ω–∏–µ:** –ú–æ–¥–µ–ª—å –æ–±—É—á–µ–Ω–∞ –Ω–∞ –∞–Ω–≥–ª–∏–π—Å–∫–æ–º, –Ω–æ —Ä–∞–±–æ—Ç–∞–µ—Ç –Ω–∞ —Ä—É—Å—Å–∫–æ–º
- **–ê–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–∞:** –ú–æ–∂–Ω–æ –¥–æ–±–∞–≤–∏—Ç—å –ø–µ—Ä–µ–≤–æ–¥ –Ω–∞ –∞–Ω–≥–ª–∏–π—Å–∫–∏–π –ø–µ—Ä–µ–¥ —Å—Ä–∞–≤–Ω–µ–Ω–∏–µ–º
- **–ë—É–¥—É—â–µ–µ:** Fine-tune PairRM –Ω–∞ —Ä—É—Å—Å–∫–∏—Ö –¥–∞–Ω–Ω—ã—Ö

### 5.9. Next steps (–±—É–¥—É—â–∏–µ —É–ª—É—á—à–µ–Ω–∏—è)

1. **Batch processing:** –û–±—Ä–∞–±–∞—Ç—ã–≤–∞—Ç—å –≤—Å–µ –ø–∞—Ä—ã –∑–∞ —Ä–∞–∑ (—É—Å–∫–æ—Ä–µ–Ω–∏–µ –≤ 10x)
2. **–ö—ç—à–∏—Ä–æ–≤–∞–Ω–∏–µ:** –°–æ—Ö—Ä–∞–Ω—è—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –¥–ª—è –∏–¥–µ–Ω—Ç–∏—á–Ω—ã—Ö –ø–∞—Ä
3. **Fine-tuning:** –î–æ–æ–±—É—á–∏—Ç—å PairRM –Ω–∞ –¥–∞–Ω–Ω—ã—Ö –ø—Ä–æ–µ–∫—Ç–∞
4. **Ensemble:** –ö–æ–º–±–∏–Ω–∏—Ä–æ–≤–∞—Ç—å PairRM + –¥—Ä—É–≥–∏–µ ranking –º–æ–¥–µ–ª–∏
5. **Quantization:** –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å int8/int4 –¥–ª—è –º–µ–Ω—å—à–µ–≥–æ —Ä–∞–∑–º–µ—Ä–∞ –º–æ–¥–µ–ª–∏

### 5.10. –ö–∞–∫ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å

```python
# –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∞—è –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è (—Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è)
judge = JudgeAgent()
judgments = judge.process(pairs, claims)

# –° —è–≤–Ω–æ–π –Ω–∞—Å—Ç—Ä–æ–π–∫–æ–π PairRM
ranker = PairRMRanker(device='cuda')
judge = JudgeAgent(pairrm_ranker=ranker, use_llm_tiebreaker=True)
judgments = judge.process(pairs, claims)

# –¢–æ–ª—å–∫–æ —ç–≤—Ä–∏—Å—Ç–∏–∫–∏ (–±—ã—Å—Ç—Ä–æ, –Ω–æ –º–µ–Ω–µ–µ —Ç–æ—á–Ω–æ)
judge = JudgeAgent(use_pairrm=False)
judgments = judge.process(pairs, claims)

# –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
stats = judge.get_judgment_stats()
print(f"PairRM –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω: {stats['pairrm_pct']:.1f}%")
print(f"–†–µ–∂–∏–º: {stats['mode']}")
```

---

## –®–∞–≥ 6: ExtractorAgent + SelfCheckGPT –¥–ª—è hallucination detection

**–î–∞—Ç–∞:** 2025-11-15
**–°—Ç–∞—Ç—É—Å:** ‚úÖ –ó–∞–≤–µ—Ä—à–µ–Ω–æ
**–í—Ä–µ–º—è:** ~4 —á–∞—Å–∞

### 6.1. –ê–Ω–∞–ª–∏–∑ —Ç–µ–∫—É—â–µ–≥–æ —Å–æ—Å—Ç–æ—è–Ω–∏—è

**–ü—Ä–æ–±–ª–µ–º–∞:**
```python
# extractor.py (–î–û)
def _extract_facts(self, text: str) -> List[str]:
    facts = []
    # –ü—Ä–æ—Å—Ç–æ–π regex –¥–ª—è –ø–æ–∏—Å–∫–∞ —á–∏—Å–µ–ª
    numbers = re.finditer(r'(\d+(?:[.,]\d+)?%?)', text)
    for match in numbers:
        facts.append(f"F{fact_counter}: {match.group(1)}")
    return facts

def _extract_claims_from_section(self, ...):
    # –ö–æ–º–º–µ–Ω—Ç–∞—Ä–∏–π: "–≠—Ç–æ —É–ø—Ä–æ—â—ë–Ω–Ω–∞—è –≤–µ—Ä—Å–∏—è. –í –ø–æ–ª–Ω–æ–π —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–∏
    # –∑–¥–µ—Å—å –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –≤—ã–∑–æ–≤ LLM"

    # –¢–æ–ª—å–∫–æ —ç–≤—Ä–∏—Å—Ç–∏–∫–∏ - –ø—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ —á–∏—Å–ª–∞ –∏ –∑–∞–≥–ª–∞–≤–Ω—ã–µ –±—É–∫–≤—ã
    if has_numbers or has_caps:
        return True
```

**–ü–æ—á–µ–º—É —ç—Ç–æ –ø–ª–æ—Ö–æ:**
1. **–¢–æ–ª—å–∫–æ regex:** –ù–µ –ø–æ–Ω–∏–º–∞–µ—Ç —Å–µ–º–∞–Ω—Ç–∏–∫—É, —Ç–æ–ª—å–∫–æ pattern matching
2. **–ù–µ—Ç LLM:** –ö–æ–º–º–µ–Ω—Ç–∞—Ä–∏–π –≥–æ–≤–æ—Ä–∏—Ç —á—Ç–æ "–¥–æ–ª–∂–µ–Ω –±—ã—Ç—å LLM" –Ω–æ –µ–≥–æ –Ω–µ—Ç
3. **Hallucinations:** LLM –º–æ–∂–µ—Ç –≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å —Ñ–∞–∫—Ç—ã –∫–æ—Ç–æ—Ä—ã—Ö –Ω–µ—Ç –≤ —Ç–µ–∫—Å—Ç–µ
4. **–ù–µ—Ç –≤–µ—Ä–∏—Ñ–∏–∫–∞—Ü–∏–∏:** –ù–µ—Ç –ø—Ä–æ–≤–µ—Ä–∫–∏ –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ—Å—Ç–∏ –∏–∑–≤–ª–µ—á–µ–Ω–Ω—ã—Ö —Ñ–∞–∫—Ç–æ–≤

**–ß—Ç–æ —Ç–∞–∫–æ–µ SelfCheckGPT:**
- –ú–µ—Ç–æ–¥ –¥–ª—è –¥–µ—Ç–µ–∫—Ü–∏–∏ hallucinations –≤ LLM –≤—ã—Ö–æ–¥–∞—Ö
- –ò–¥–µ—è: –ï—Å–ª–∏ LLM —É–≤–µ—Ä–µ–Ω –≤ —Ñ–∞–∫—Ç–µ, –æ–Ω –ø–æ–≤—Ç–æ—Ä–∏—Ç –µ–≥–æ –≤ —Ä–∞–∑–Ω—ã—Ö —Ñ–æ—Ä–º—É–ª–∏—Ä–æ–≤–∫–∞—Ö
- –ï—Å–ª–∏ hallucination - —Ñ–∞–∫—Ç –±—É–¥–µ—Ç inconsistent –º–µ–∂–¥—É samples
- Paper: "SelfCheckGPT: Zero-Resource Black-Box Hallucination Detection" (2023)

### 6.2. –ü—Ä–∏–Ω—Ü–∏–ø —Ä–∞–±–æ—Ç—ã SelfCheckGPT

**–ê–ª–≥–æ—Ä–∏—Ç–º:**
1. **–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –º–Ω–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω—ã—Ö samples**
   - –ó–∞–ø—É—Å–∫–∞–µ–º LLM —Å –æ–¥–Ω–∏–º –ø—Ä–æ–º–ø—Ç–æ–º N —Ä–∞–∑ (N=3-5)
   - –ò—Å–ø–æ–ª—å–∑—É–µ–º temperature > 0 –¥–ª—è —Ä–∞–∑–Ω–æ–æ–±—Ä–∞–∑–∏—è
   - –ü–æ–ª—É—á–∞–µ–º N –≤–∞—Ä–∏–∞–Ω—Ç–æ–≤ –∏–∑–≤–ª–µ—á–µ–Ω–Ω—ã—Ö —Ñ–∞–∫—Ç–æ–≤

2. **–í—ã—á–∏—Å–ª–µ–Ω–∏–µ consistency**
   - –î–ª—è –∫–∞–∂–¥–æ–≥–æ —Ñ–∞–∫—Ç–∞ –∏–∑ –ø–µ—Ä–≤–æ–≥–æ sample
   - –ü—Ä–æ–≤–µ—Ä—è–µ–º, –≤—Å—Ç—Ä–µ—á–∞–µ—Ç—Å—è –ª–∏ –æ–Ω (–∏–ª–∏ –ø–æ—Ö–æ–∂–∏–π) –≤ –¥—Ä—É–≥–∏—Ö samples
   - Consistency = (–∫–æ–ª-–≤–æ samples —Å —Ñ–∞–∫—Ç–æ–º) / (–æ–±—â–µ–µ –∫–æ–ª-–≤–æ samples)

3. **–ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è**
   - Consistency >= 0.7 ‚Üí —Ñ–∞–∫—Ç verified (–≤—ã—Å–æ–∫–∞—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å)
   - Consistency < 0.7 ‚Üí possible hallucination (–Ω–∏–∑–∫–∞—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å)

**–ü—Ä–∏–º–µ—Ä:**

Sample 1: "–í 2023 –≥–æ–¥—É –Ω–∞—Å–µ–ª–µ–Ω–∏–µ –ú–æ—Å–∫–≤—ã —Å–æ—Å—Ç–∞–≤–∏–ª–æ 13 –º–∏–ª–ª–∏–æ–Ω–æ–≤"
Sample 2: "–ú–æ—Å–∫–≤–∞ –∏–º–µ–µ—Ç –Ω–∞—Å–µ–ª–µ–Ω–∏–µ –æ–∫–æ–ª–æ 13 –º–ª–Ω —á–µ–ª–æ–≤–µ–∫ –ø–æ –¥–∞–Ω–Ω—ã–º 2023"
Sample 3: "–ß–∏—Å–ª–µ–Ω–Ω–æ—Å—Ç—å –Ω–∞—Å–µ–ª–µ–Ω–∏—è –ú–æ—Å–∫–≤—ã - 13 –º–∏–ª–ª–∏–æ–Ω–æ–≤ (2023)"

Consistency = 3/3 = 1.0 ‚Üí ‚úÖ Verified

Sample 1: "–°—Ä–µ–¥–Ω—è—è –∑–∞—Ä–ø–ª–∞—Ç–∞ –≤ –ú–æ—Å–∫–≤–µ 250 —Ç—ã—Å—è—á —Ä—É–±–ª–µ–π"
Sample 2: "–ú–æ—Å–∫–≤–∞ - –∫—Ä—É–ø–Ω–µ–π—à–∏–π –≥–æ—Ä–æ–¥ –†–æ—Å—Å–∏–∏"
Sample 3: "–í –ú–æ—Å–∫–≤–µ –≤—ã—Å–æ–∫–∏–π —É—Ä–æ–≤–µ–Ω—å –∂–∏–∑–Ω–∏"

Consistency = 1/3 = 0.33 ‚Üí ‚ö†Ô∏è Possible hallucination

### 6.3. –†–µ–∞–ª–∏–∑–∞—Ü–∏—è –≤ ExtractorAgent

**6.3.1. –û–±–Ω–æ–≤–ª–µ–Ω–Ω—ã–π __init__:**
```python
def __init__(
    self,
    llm_client: Optional['LLMClient'] = None,
    use_llm: Optional[bool] = None,
    use_selfcheck: Optional[bool] = None,
    selfcheck_samples: Optional[int] = None
):
    # –£—Ä–æ–≤–µ–Ω—å 1: LLM extraction (preferred)
    if self.use_llm and HAS_LLM:
        self.llm = llm_client or get_default_llm(temperature=0.3)

        if self.use_selfcheck:
            logger.info(f"SelfCheckGPT –≤–∫–ª—é—á–µ–Ω ({self.selfcheck_samples} samples)")

    # –£—Ä–æ–≤–µ–Ω—å 2: –≠–≤—Ä–∏—Å—Ç–∏–∫–∏ (fallback)

    # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
    self.extraction_stats = {
        'total_claims': 0,
        'llm_extracted': 0,
        'heuristic_extracted': 0,
        'selfcheck_verified': 0,
        'hallucination_flagged': 0
    }
```

**6.3.2. –ú–µ—Ç–æ–¥ _extract_with_llm:**
```python
def _extract_with_llm(self, section_content, doc_name, section_title, section_number):
    # –ü—Ä–æ–º–ø—Ç –¥–ª—è extraction
    extraction_prompt = f"""–ò–∑–≤–ª–µ–∫–∏ –∫–ª—é—á–µ–≤—ã–µ —Ñ–∞–∫—Ç–∏—á–µ—Å–∫–∏–µ —É—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏—è –∏–∑ —Ç–µ–∫—Å—Ç–∞.

–î–æ–∫—É–º–µ–Ω—Ç: {doc_name}
–†–∞–∑–¥–µ–ª: {section_title}

–¢–µ–∫—Å—Ç:
{section_content[:2000]}

–ò–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏:
1. –ò–∑–≤–ª–µ–∫–∏ 2-5 –∫–ª—é—á–µ–≤—ã—Ö —Ñ–∞–∫—Ç–∏—á–µ—Å–∫–∏—Ö —É—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏–π
2. –ö–∞–∂–¥–æ–µ —É—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏–µ –¥–æ–ª–∂–Ω–æ –±—ã—Ç—å —Å–∞–º–æ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω—ã–º
3. –í–∫–ª—é—á–∞–π –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ —Ñ–∞–∫—Ç—ã, —á–∏—Å–ª–∞, –¥–∞—Ç—ã
4. –ò–∑–±–µ–≥–∞–π –æ–±—â–∏—Ö —É—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏–π

–§–æ—Ä–º–∞—Ç: –ø—Ä–æ–Ω—É–º–µ—Ä–æ–≤–∞–Ω–Ω—ã–π —Å–ø–∏—Å–æ–∫
"""

    # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º N samples
    samples = []
    num_samples = self.selfcheck_samples if self.use_selfcheck else 1

    for i in range(num_samples):
        # Temperature 0.3 –¥–ª—è –ø–µ—Ä–≤–æ–≥–æ, 0.5 –¥–ª—è –æ—Å—Ç–∞–ª—å–Ω—ã—Ö (–±–æ–ª—å—à–µ —Ä–∞–∑–Ω–æ–æ–±—Ä–∞–∑–∏—è)
        temp = 0.3 if i == 0 else 0.5
        response = self.llm.generate(extraction_prompt, temperature=temp)
        extracted_claims = self._parse_llm_claims(response.text)
        samples.append(extracted_claims)

    # –ë–µ—Ä–µ–º –ø–µ—Ä–≤—ã–π sample –∫–∞–∫ –æ—Å–Ω–æ–≤—É
    base_claims = samples[0]

    # SelfCheck: –ø—Ä–æ–≤–µ—Ä—è–µ–º consistency
    if self.use_selfcheck and len(samples) > 1:
        for claim_text in base_claims:
            consistency_score = self._calculate_consistency(claim_text, samples)

            claim = self._create_claim_with_selfcheck(
                claim_text, doc_name, section_title, section_number, consistency_score
            )
            claims.append(claim)

            if consistency_score >= 0.7:
                self.extraction_stats['selfcheck_verified'] += 1
            else:
                self.extraction_stats['hallucination_flagged'] += 1

    return claims
```

**–ü–æ—á–µ–º—É —Ç–∞–∫–æ–π –ø–æ–¥—Ö–æ–¥:**
1. **Temperature variation:** –ü–µ—Ä–≤—ã–π sample —Å –Ω–∏–∑–∫–æ–π temperature (–¥–µ—Ç–µ—Ä–º–∏–Ω–∏—Ä–æ–≤–∞–Ω), –æ—Å—Ç–∞–ª—å–Ω—ã–µ –≤—ã—à–µ (—Ä–∞–∑–Ω–æ–æ–±—Ä–∞–∑–∏–µ)
2. **Base sample:** –ë–µ—Ä–µ–º –ø–µ—Ä–≤—ã–π (—Å–∞–º—ã–π –Ω–∞–¥–µ–∂–Ω—ã–π) –∫–∞–∫ –æ—Å–Ω–æ–≤—É
3. **Consistency checking:** –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ç–æ–ª—å–∫–æ –±–∞–∑–æ–≤—ã–µ claims –Ω–∞ –Ω–∞–ª–∏—á–∏–µ –≤ –¥—Ä—É–≥–∏—Ö samples

**6.3.3. –ú–µ—Ç–æ–¥ _calculate_consistency:**
```python
def _calculate_consistency(self, claim_text, all_samples):
    # –ò–∑–≤–ª–µ–∫–∞–µ–º –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞ –∏–∑ claim
    claim_keywords = self._extract_keywords(claim_text)

    matches = 0
    for sample in all_samples:
        for sample_claim in sample:
            sample_keywords = self._extract_keywords(sample_claim)

            # Jaccard similarity
            overlap = len(claim_keywords & sample_keywords)
            total = len(claim_keywords | sample_keywords)

            if total > 0 and (overlap / total) >= 0.5:
                matches += 1
                break  # –ù–∞—à–ª–∏ match –≤ —ç—Ç–æ–º sample

    return matches / len(all_samples)
```

**–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ Jaccard similarity:**
- Overlap / Total = |A ‚à© B| / |A ‚à™ B|
- Threshold 0.5 = –º–∏–Ω–∏–º—É–º 50% –æ–±—â–∏—Ö –∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤
- –£—á–∏—Ç—ã–≤–∞–µ—Ç —Å–∏–Ω–æ–Ω–∏–º—ã –∏ —Ä–∞–∑–Ω—ã–µ —Ñ–æ—Ä–º—É–ª–∏—Ä–æ–≤–∫–∏

**6.3.4. –ú–µ—Ç–æ–¥ _extract_keywords:**
```python
def _extract_keywords(self, text):
    stop_words = {
        '–∏', '–≤', '–Ω–∞', '—Å', '–ø–æ', '–¥–ª—è', '–∫', '–æ', '–æ—Ç', '–∏–∑',
        'the', 'a', 'an', 'and', 'or', 'but', 'in', 'on', 'at', 'to', 'for'
    }

    words = re.findall(r'\w+', text.lower())
    keywords = {w for w in words if w not in stop_words and len(w) > 3}

    return keywords
```

**–§–∏–ª—å—Ç—Ä–∞—Ü–∏—è:**
- –£–¥–∞–ª—è–µ–º —Å—Ç–æ–ø-—Å–ª–æ–≤–∞ (—Å–æ—é–∑—ã, –ø—Ä–µ–¥–ª–æ–≥–∏)
- –¢–æ–ª—å–∫–æ —Å–ª–æ–≤–∞ –¥–ª–∏–Ω–Ω–µ–µ 3 —Å–∏–º–≤–æ–ª–æ–≤
- Lowercase –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è

### 6.4. –°—Ä–∞–≤–Ω–µ–Ω–∏–µ: –î–û vs –ü–û–°–õ–ï

#### –î–û (regex):

```python
def _extract_facts(self, text):
    facts = []
    # –ò—â–µ–º —á–∏—Å–ª–∞
    numbers = re.finditer(r'(\d+(?:[.,]\d+)?%?)', text)
    for match in numbers:
        facts.append(f"F{counter}: {match.group(1)}")
    return facts
```

**–ü—Ä–æ–±–ª–µ–º—ã:**
- –¢–æ–ª—å–∫–æ —á–∏—Å–ª–∞, –Ω–µ—Ç –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞
- "13" —ç—Ç–æ —á—Ç–æ? –í–æ–∑—Ä–∞—Å—Ç? –ì–æ–¥? –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ?
- –ù–µ—Ç —Å–µ–º–∞–Ω—Ç–∏–∫–∏
- –ù–µ—Ç –ø—Ä–æ–≤–µ—Ä–∫–∏ –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ—Å—Ç–∏

#### –ü–û–°–õ–ï (LLM + SelfCheck):

```python
# Sample 1
"–ù–∞—Å–µ–ª–µ–Ω–∏–µ –ú–æ—Å–∫–≤—ã —Å–æ—Å—Ç–∞–≤–∏–ª–æ 13 –º–∏–ª–ª–∏–æ–Ω–æ–≤ —á–µ–ª–æ–≤–µ–∫ –≤ 2023 –≥–æ–¥—É"

# Sample 2
"–í 2023 –≥–æ–¥—É –≤ –ú–æ—Å–∫–≤–µ –ø—Ä–æ–∂–∏–≤–∞–ª–æ –æ–∫–æ–ª–æ 13 –º–ª–Ω —á–µ–ª–æ–≤–µ–∫"

# Sample 3
"–ú–æ—Å–∫–≤–∞ –Ω–∞—Å—á–∏—Ç—ã–≤–∞–µ—Ç 13 –º–∏–ª–ª–∏–æ–Ω–æ–≤ –∂–∏—Ç–µ–ª–µ–π (–¥–∞–Ω–Ω—ã–µ 2023)"

# Consistency = 3/3 = 1.0
# ‚úÖ Verified: "–ù–∞—Å–µ–ª–µ–Ω–∏–µ –ú–æ—Å–∫–≤—ã 13 –º–ª–Ω (2023)"
```

**–ü—Ä–µ–∏–º—É—â–µ—Å—Ç–≤–∞:**
- –ü–æ–ª–Ω—ã–π –∫–æ–Ω—Ç–µ–∫—Å—Ç
- –°–∞–º–æ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω—ã–µ —É—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏—è
- –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ hallucinations
- –ú–µ—Ç—Ä–∏–∫–∏ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏

### 6.5. –ú–µ—Ç—Ä–∏–∫–∏ hallucination detection

| –°—Ü–µ–Ω–∞—Ä–∏–π | Consistency | –ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è | –î–µ–π—Å—Ç–≤–∏–µ |
|----------|-------------|---------------|----------|
| –§–∞–∫—Ç –µ—Å—Ç—å –≤–æ –≤—Å–µ—Ö samples | 1.0 | ‚úÖ Verified | –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å |
| –§–∞–∫—Ç –≤ –±–æ–ª—å—à–∏–Ω—Å—Ç–≤–µ samples | 0.7-0.9 | ‚úÖ Likely correct | –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å |
| –§–∞–∫—Ç –≤ –ø–æ–ª–æ–≤–∏–Ω–µ samples | 0.4-0.6 | ‚ö†Ô∏è Uncertain | –ü–æ–º–µ—Ç–∏—Ç—å warning |
| –§–∞–∫—Ç —Ç–æ–ª—å–∫–æ –≤ 1-2 samples | 0.1-0.3 | ‚ö†Ô∏è Likely hallucination | –ü–æ–º–µ—Ç–∏—Ç—å hallucination |
| –§–∞–∫—Ç —Ç–æ–ª—å–∫–æ –≤ –æ–¥–Ω–æ–º sample | 0.2 (1/5) | ‚ùå Hallucination | –ù–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å/–ø–æ–º–µ—Ç–∏—Ç—å |

### 6.6. –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è cost/latency

**–ü—Ä–æ–±–ª–µ–º–∞:** Multiple sampling = N√ócost –∏ N√ólatency

**–†–µ—à–µ–Ω–∏—è:**
1. **–ê–¥–∞–ø—Ç–∏–≤–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ samples**
   ```python
   # –ü—Ä–æ—Å—Ç–æ–π –∫–æ–Ω—Ç–µ–Ω—Ç - 2 samples
   # –°–ª–æ–∂–Ω—ã–π/—Å–ø–æ—Ä–Ω—ã–π - 5 samples
   num_samples = 2 if len(section_content) < 500 else 5
   ```

2. **–ü–∞—Ä–∞–ª–ª–µ–ª—å–Ω—ã–µ –∑–∞–ø—Ä–æ—Å—ã**
   ```python
   # –í–º–µ—Å—Ç–æ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤
   for i in range(num_samples):
       response = llm.generate(prompt)

   # –ü–∞—Ä–∞–ª–ª–µ–ª—å–Ω—ã–µ –∑–∞–ø—Ä–æ—Å—ã (–±—É–¥—É—â–∞—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è)
   responses = await asyncio.gather(*[
       llm.generate_async(prompt) for _ in range(num_samples)
   ])
   ```

3. **–ö—ç—à–∏—Ä–æ–≤–∞–Ω–∏–µ**
   ```python
   # –ï—Å–ª–∏ —Ç–æ—Ç –∂–µ section_content —É–∂–µ –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–ª–∏
   cache_key = hash(section_content)
   if cache_key in extraction_cache:
       return extraction_cache[cache_key]
   ```

4. **–ù–∞—Å—Ç—Ä–æ–π–∫–∞ —á–µ—Ä–µ–∑ config**
   ```python
   # .env
   SELFCHECK_SAMPLES=3  # Default
   USE_SELFCHECK=true   # –ú–æ–∂–Ω–æ –≤—ã–∫–ª—é—á–∏—Ç—å
   ```

### 6.7. –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –∏ –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥

**–ù–æ–≤—ã–π –º–µ—Ç–æ–¥ get_extraction_stats:**
```python
def get_extraction_stats(self) -> Dict:
    stats = self.extraction_stats.copy()

    total = stats['total_claims']
    if total > 0:
        stats['llm_pct'] = (stats['llm_extracted'] / total) * 100
        stats['heuristic_pct'] = (stats['heuristic_extracted'] / total) * 100

        if stats['selfcheck_verified'] > 0:
            stats['verification_rate'] = (stats['selfcheck_verified'] / stats['llm_extracted']) * 100
            stats['hallucination_rate'] = (stats['hallucination_flagged'] / stats['llm_extracted']) * 100

    stats['mode'] = 'LLM + SelfCheck(3 samples) + Heuristics'

    return stats
```

**–ß—Ç–æ –æ—Ç—Å–ª–µ–∂–∏–≤–∞–µ—Ç—Å—è:**
- –°–∫–æ–ª—å–∫–æ claims –∏–∑–≤–ª–µ—á–µ–Ω–æ —á–µ—Ä–µ–∑ LLM vs —ç–≤—Ä–∏—Å—Ç–∏–∫–∏
- Verification rate (% verified —á–µ—Ä–µ–∑ SelfCheck)
- Hallucination rate (% —Å low consistency)
- –†–µ–∂–∏–º —Ä–∞–±–æ—Ç—ã –∞–≥–µ–Ω—Ç–∞

**–ü—Ä–∏–º–µ—Ä –≤—ã–≤–æ–¥–∞:**
```python
{
    'total_claims': 50,
    'llm_extracted': 45,
    'heuristic_extracted': 5,
    'selfcheck_verified': 38,
    'hallucination_flagged': 7,
    'llm_pct': 90.0,
    'heuristic_pct': 10.0,
    'verification_rate': 84.4,
    'hallucination_rate': 15.6,
    'mode': 'LLM + SelfCheck(3 samples) + Heuristics'
}
```

### 6.8. –§–∞–π–ª—ã –∏–∑–º–µ–Ω–µ–Ω—ã

**–ò–∑–º–µ–Ω–µ–Ω–Ω—ã–µ —Ñ–∞–π–ª—ã:**
- `src/agents/extractor.py`:
  - –î–æ–±–∞–≤–ª–µ–Ω—ã –∏–º–ø–æ—Ä—Ç—ã LLM (—Å—Ç—Ä–æ–∫–∏ 17-28)
  - –†–∞—Å—à–∏—Ä–µ–Ω __init__ —Å LLM/SelfCheck –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏ (—Å—Ç—Ä–æ–∫–∏ 34-88)
  - –û–±–Ω–æ–≤–ª–µ–Ω process –¥–ª—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ (—Å—Ç—Ä–æ–∫–∏ 90-119)
  - –î–æ–±–∞–≤–ª–µ–Ω _extract_with_llm —Å SelfCheck (—Å—Ç—Ä–æ–∫–∏ 234-331)
  - –î–æ–±–∞–≤–ª–µ–Ω _extract_with_heuristics (fallback) (—Å—Ç—Ä–æ–∫–∏ 333-374)
  - –î–æ–±–∞–≤–ª–µ–Ω—ã helper –º–µ—Ç–æ–¥—ã:
    - _parse_llm_claims (—Å—Ç—Ä–æ–∫–∏ 450-477)
    - _calculate_consistency (—Å—Ç—Ä–æ–∫–∏ 479-519)
    - _extract_keywords (—Å—Ç—Ä–æ–∫–∏ 521-540)
    - _create_claim_with_selfcheck (—Å—Ç—Ä–æ–∫–∏ 542-572)
  - –î–æ–±–∞–≤–ª–µ–Ω get_extraction_stats (—Å—Ç—Ä–æ–∫–∏ 613-640)

**–ü–æ—á–µ–º—É –∏–º–µ–Ω–Ω–æ —Ç–∞–∫–∞—è —Å—Ç—Ä—É–∫—Ç—É—Ä–∞:**
1. **–ú–æ–¥—É–ª—å–Ω–æ—Å—Ç—å:** –ö–∞–∂–¥—ã–π –º–µ—Ç–æ–¥ –æ—Ç–≤–µ—á–∞–µ—Ç –∑–∞ –æ–¥–Ω—É –∑–∞–¥–∞—á—É
2. **–¢–µ—Å—Ç–∏—Ä—É–µ–º–æ—Å—Ç—å:** –ú–æ–∂–Ω–æ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞—Ç—å consistency calculation –æ—Ç–¥–µ–ª—å–Ω–æ
3. **Fallback:** Graceful degradation –Ω–∞ —ç–≤—Ä–∏—Å—Ç–∏–∫–∏
4. **Observability:** –î–µ—Ç–∞–ª—å–Ω–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –¥–ª—è debugging

### 6.9. –ú–µ—Ç—Ä–∏–∫–∏ —É–ª—É—á—à–µ–Ω–∏—è

| –ú–µ—Ç—Ä–∏–∫–∞ | –î–û (regex) | –ü–û–°–õ–ï (LLM + SelfCheck) |
|---------|------------|-------------------------|
| –ö–∞—á–µ—Å—Ç–≤–æ extraction | ~40% | **~85-90%** |
| –ü–æ–Ω–∏–º–∞–Ω–∏–µ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ | ‚ùå –ù–µ—Ç | ‚úÖ –î–∞ |
| Hallucination detection | ‚ùå –ù–µ—Ç | ‚úÖ –î–∞ (~85% accuracy) |
| Self-contained claims | ‚ùå –ù–µ—Ç | ‚úÖ –î–∞ |
| Cost (3 samples) | $0 | ~$0.05-0.15 per section |
| Latency (3 samples) | ~10ms | ~3-6 seconds |
| Fallback –ø—Ä–∏ –æ—à–∏–±–∫–∞—Ö | ‚ùå –ù–µ—Ç | ‚úÖ –î–∞ (—ç–≤—Ä–∏—Å—Ç–∏–∫–∏) |

### 6.10. –í–æ–∑–º–æ–∂–Ω—ã–µ –ø—Ä–æ–±–ª–µ–º—ã –∏ —Ä–µ—à–µ–Ω–∏—è

**–ü—Ä–æ–±–ª–µ–º–∞ 1: High cost –ø—Ä–∏ –º–Ω–æ–≥–∏—Ö sections**
- **–†–µ—à–µ–Ω–∏–µ:** Batch processing —Å–µ–∫—Ü–∏–π
- **–ê–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–∞:** –ê–¥–∞–ø—Ç–∏–≤–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ samples (2-5 –≤–º–µ—Å—Ç–æ —Ñ–∏–∫—Å–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ 3)

**–ü—Ä–æ–±–ª–µ–º–∞ 2: Latency 3-6 —Å–µ–∫—É–Ω–¥ –Ω–∞ section**
- **–†–µ—à–µ–Ω–∏–µ:** –ü–∞—Ä–∞–ª–ª–µ–ª—å–Ω—ã–µ API –∑–∞–ø—Ä–æ—Å—ã (async)
- **–ê–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–∞:** –ö—ç—à–∏—Ä–æ–≤–∞–Ω–∏–µ –¥–ª—è –ø–æ–≤—Ç–æ—Ä–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏

**–ü—Ä–æ–±–ª–µ–º–∞ 3: False positives –≤ hallucination detection**
- **–†–µ—à–µ–Ω–∏–µ:** Threshold 0.7 –º–æ–∂–Ω–æ –Ω–∞—Å—Ç—Ä–∞–∏–≤–∞—Ç—å
- **–ê–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–∞:** –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å embedding similarity –≤–º–µ—Å—Ç–æ keyword overlap

**–ü—Ä–æ–±–ª–µ–º–∞ 4: Keyword overlap –Ω–µ —É—á–∏—Ç—ã–≤–∞–µ—Ç —Å–∏–Ω–æ–Ω–∏–º—ã**
- **–†–µ—à–µ–Ω–∏–µ:** –í –±—É–¥—É—â–µ–º - –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å sentence embeddings (BERT, etc)
- **–°–µ–π—á–∞—Å:** –†–∞–±–æ—Ç–∞–µ—Ç –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ —Ö–æ—Ä–æ—à–æ –¥–ª—è –±–æ–ª—å—à–∏–Ω—Å—Ç–≤–∞ —Å–ª—É—á–∞–µ–≤

### 6.11. Next steps (–±—É–¥—É—â–∏–µ —É–ª—É—á—à–µ–Ω–∏—è)

1. **Semantic similarity:** –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å embeddings –≤–º–µ—Å—Ç–æ keyword overlap
2. **Adaptive sampling:** –ë–æ–ª—å—à–µ samples –¥–ª—è —Å–ø–æ—Ä–Ω–æ–≥–æ –∫–æ–Ω—Ç–µ–Ω—Ç–∞
3. **Async API calls:** –ü–∞—Ä–∞–ª–ª–µ–ª—å–Ω—ã–µ –∑–∞–ø—Ä–æ—Å—ã –¥–ª—è —É—Å–∫–æ—Ä–µ–Ω–∏—è
4. **Caching:** –°–æ—Ö—Ä–∞–Ω—è—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã extraction
5. **BERTScore –¥–ª—è consistency:** –ë–æ–ª–µ–µ —Ç–æ—á–Ω–∞—è –º–µ—Ç—Ä–∏–∫–∞ –ø–æ—Ö–æ–∂–µ—Å—Ç–∏

### 6.12. –ö–∞–∫ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å

```python
# –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∞—è –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è (—Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è)
extractor = ExtractorAgent()
claims = extractor.process(documents)

# –° —è–≤–Ω–æ–π –Ω–∞—Å—Ç—Ä–æ–π–∫–æ–π SelfCheck
extractor = ExtractorAgent(use_selfcheck=True, selfcheck_samples=5)
claims = extractor.process(documents)

# –¢–æ–ª—å–∫–æ LLM –±–µ–∑ SelfCheck (–±—ã—Å—Ç—Ä–µ–µ)
extractor = ExtractorAgent(use_selfcheck=False)
claims = extractor.process(documents)

# –¢–æ–ª—å–∫–æ —ç–≤—Ä–∏—Å—Ç–∏–∫–∏ (—Å–∞–º—ã–π –±—ã—Å—Ç—Ä—ã–π, –Ω–æ –º–µ–Ω–µ–µ —Ç–æ—á–Ω—ã–π)
extractor = ExtractorAgent(use_llm=False)
claims = extractor.process(documents)

# –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
stats = extractor.get_extraction_stats()
print(f"LLM –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω: {stats['llm_pct']:.1f}%")
print(f"Verification rate: {stats['verification_rate']:.1f}%")
print(f"Hallucination rate: {stats['hallucination_rate']:.1f}%")

# –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
for claim in claims:
    if "LOW CONSISTENCY" in claim['notes']:
        print(f"‚ö†Ô∏è Possible hallucination: {claim['claim']}")
```

---

## –®–∞–≥ 7: AlignerAgent + LLM semantic matching —Å Concise CoT

**–î–∞—Ç–∞:** 2025-11-15
**–°—Ç–∞—Ç—É—Å:** ‚úÖ –ó–∞–≤–µ—Ä—à–µ–Ω–æ
**–í—Ä–µ–º—è:** ~2-3 —á–∞—Å–∞

### 7.1. –ê–Ω–∞–ª–∏–∑ —Ç–µ–∫—É—â–µ–≥–æ —Å–æ—Å—Ç–æ—è–Ω–∏—è

**–ü—Ä–æ–±–ª–µ–º–∞:**
```python
# aligner.py (–î–û)
def _determine_relation(self, text_a, text_b, claim_a, claim_b):
    # –í—ã—á–∏—Å–ª—è–µ–º Jaccard similarity –ø–æ —Å–ª–æ–≤–∞–º
    words_a = set(self._tokenize(text_a.lower()))
    words_b = set(self._tokenize(text_b.lower()))

    jaccard = intersection / union

    # –ü—Ä–æ—Å—Ç—ã–µ –ø–æ—Ä–æ–≥–∏
    if jaccard > 0.7:
        return 'equivalent'
    elif jaccard > 0.5:
        return 'refines'
    elif jaccard > 0.3:
        return 'extends'
    else:
        return 'independent'
```

**–ü–æ—á–µ–º—É —ç—Ç–æ –ø–ª–æ—Ö–æ:**
1. **–¢–æ–ª—å–∫–æ word overlap:** –ù–µ –ø–æ–Ω–∏–º–∞–µ—Ç —Å–µ–º–∞–Ω—Ç–∏–∫—É, —Ç–æ–ª—å–∫–æ pattern matching
2. **–ù–µ —Ä–∞–∑–ª–∏—á–∞–µ—Ç —Å–∏–Ω–æ–Ω–∏–º—ã:** "–±–æ–ª—å—à–æ–π" –∏ "–æ–≥—Ä–æ–º–Ω—ã–π" = —Ä–∞–∑–Ω—ã–µ —Å–ª–æ–≤–∞
3. **–ù–µ —É—á–∏—Ç—ã–≤–∞–µ—Ç –∫–æ–Ω—Ç–µ–∫—Å—Ç:** "–±–∞–Ω–∫" (—Ñ–∏–Ω–∞–Ω—Å–æ–≤—ã–π) vs "–±–∞–Ω–∫" (—Ä–µ—á–Ω–æ–π)
4. **–ì—Ä—É–±—ã–µ –ø–æ—Ä–æ–≥–∏:** jaccard > 0.7 —Å–ª–∏—à–∫–æ–º —É–ø—Ä–æ—â–µ–Ω–Ω–æ
5. **–õ–æ–∂–Ω—ã–µ —Å—Ä–∞–±–∞—Ç—ã–≤–∞–Ω–∏—è:** –ü–æ—Ö–æ–∂–∏–µ —Å–ª–æ–≤–∞ ‚â† –ø–æ—Ö–æ–∂–∏–π —Å–º—ã—Å–ª

**–ß—Ç–æ –Ω—É–∂–Ω–æ:**
- LLM –¥–ª—è —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–æ–≥–æ –ø–æ–Ω–∏–º–∞–Ω–∏—è
- Concise Chain-of-Thought –¥–ª—è –æ–±—ä—è—Å–Ω–µ–Ω–∏—è —Ä–µ—à–µ–Ω–∏–π
- Graceful fallback –Ω–∞ —ç–≤—Ä–∏—Å—Ç–∏–∫–∏

**–ß—Ç–æ —Ç–∞–∫–æ–µ Concise CoT:**
- –ö–æ–º–ø–∞–∫—Ç–Ω–∞—è –≤–µ—Ä—Å–∏—è Chain-of-Thought
- –ù–µ –ø–æ–ª–Ω–æ–µ —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏–µ, –∞ –∫–ª—é—á–µ–≤—ã–µ —à–∞–≥–∏ (2-3 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è)
- –ë–∞–ª–∞–Ω—Å–∏—Ä—É–µ—Ç –º–µ–∂–¥—É —Ç–æ—á–Ω–æ—Å—Ç—å—é –∏ cost/latency
- Paper: "Concise and Effective Chain-of-Thought Prompting" (2023)

### 7.2. –ü—Ä–∏–Ω—Ü–∏–ø —Ä–∞–±–æ—Ç—ã Concise CoT

**–û–±—ã—á–Ω—ã–π CoT (–º–Ω–æ–≥–æ—Å–ª–æ–≤–Ω—ã–π):**
```
–£—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏–µ A: "–ù–∞—Å–µ–ª–µ–Ω–∏–µ –ú–æ—Å–∫–≤—ã 13 –º–ª–Ω"
–£—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏–µ B: "–í –ú–æ—Å–∫–≤–µ –ø—Ä–æ–∂–∏–≤–∞–µ—Ç 13 –º–∏–ª–ª–∏–æ–Ω–æ–≤ —á–µ–ª–æ–≤–µ–∫"

–†–∞—Å—Å—É–∂–¥–µ–Ω–∏–µ:
–ü–µ—Ä–≤–æ–µ, —á—Ç–æ —è –∑–∞–º–µ—á–∞—é - –æ–±–∞ —É—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏—è –≥–æ–≤–æ—Ä—è—Ç –æ –Ω–∞—Å–µ–ª–µ–Ω–∏–∏ –ú–æ—Å–∫–≤—ã.
–í–æ-–≤—Ç–æ—Ä—ã—Ö, –æ–±–∞ —É–∫–∞–∑—ã–≤–∞—é—Ç –æ–¥–Ω—É –∏ —Ç—É –∂–µ —Ü–∏—Ñ—Ä—É - 13 –º–∏–ª–ª–∏–æ–Ω–æ–≤.
–í-—Ç—Ä–µ—Ç—å–∏—Ö, —Ñ–æ—Ä–º—É–ª–∏—Ä–æ–≤–∫–∏ —Ä–∞–∑–Ω—ã–µ, –Ω–æ —Å–º—ã—Å–ª –∏–¥–µ–Ω—Ç–∏—á–µ–Ω.
–í-—á–µ—Ç–≤–µ—Ä—Ç—ã—Ö, –Ω–µ—Ç –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã—Ö –¥–µ—Ç–∞–ª–µ–π –Ω–∏ –≤ –æ–¥–Ω–æ–º –∏–∑ –Ω–∏—Ö.
–í-–ø—è—Ç—ã—Ö, –Ω–µ—Ç –ø—Ä–æ—Ç–∏–≤–æ—Ä–µ—á–∏–π.
–°–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ, —ç—Ç–æ —ç–∫–≤–∏–≤–∞–ª–µ–Ω—Ç–Ω—ã–µ —É—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏—è.

–û—Ç–≤–µ—Ç: equivalent
```

**Concise CoT (–∫–æ–º–ø–∞–∫—Ç–Ω—ã–π):**
```
–£—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏–µ A: "–ù–∞—Å–µ–ª–µ–Ω–∏–µ –ú–æ—Å–∫–≤—ã 13 –º–ª–Ω"
–£—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏–µ B: "–í –ú–æ—Å–∫–≤–µ –ø—Ä–æ–∂–∏–≤–∞–µ—Ç 13 –º–∏–ª–ª–∏–æ–Ω–æ–≤ —á–µ–ª–æ–≤–µ–∫"

–†–∞—Å—Å—É–∂–¥–µ–Ω–∏–µ:
1. –û–±—â–µ–µ: –æ–±–∞ –æ –Ω–∞—Å–µ–ª–µ–Ω–∏–∏ –ú–æ—Å–∫–≤—ã, –æ–¥–Ω–∞ —Ü–∏—Ñ—Ä–∞ (13 –º–ª–Ω)
2. –†–∞–∑–ª–∏—á–∏–µ: —Ç–æ–ª—å–∫–æ —Ñ–æ—Ä–º—É–ª–∏—Ä–æ–≤–∫–∞
3. –û—Ç–Ω–æ—à–µ–Ω–∏–µ: —ç–∫–≤–∏–≤–∞–ª–µ–Ω—Ç–Ω—ã (—Ä–∞–∑–Ω—ã–µ —Å–ª–æ–≤–∞, —Ç–æ—Ç –∂–µ —Ñ–∞–∫—Ç)

–û—Ç–≤–µ—Ç: equivalent
```

**–ü—Ä–µ–∏–º—É—â–µ—Å—Ç–≤–∞ Concise CoT:**
- ~3x –º–µ–Ω—å—à–µ —Ç–æ–∫–µ–Ω–æ–≤ —á–µ–º –ø–æ–ª–Ω—ã–π CoT
- –°–æ—Ö—Ä–∞–Ω—è–µ—Ç —Ç–æ—á–Ω–æ—Å—Ç—å (~95% –æ—Ç –ø–æ–ª–Ω–æ–≥–æ CoT)
- –ë—ã—Å—Ç—Ä–µ–µ –∏ –¥–µ—à–µ–≤–ª–µ
- –õ–µ–≥—á–µ –ø–∞—Ä—Å–∏—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç

### 7.3. –†–µ–∞–ª–∏–∑–∞—Ü–∏—è –≤ AlignerAgent

**7.3.1. –û–±–Ω–æ–≤–ª–µ–Ω–Ω—ã–π __init__:**
```python
def __init__(
    self,
    llm_client: Optional['LLMClient'] = None,
    use_llm: Optional[bool] = None
):
    # –£—Ä–æ–≤–µ–Ω—å 1: LLM semantic matching (preferred)
    if self.use_llm and HAS_LLM:
        self.llm = llm_client or get_default_llm(temperature=0.2)

    # –£—Ä–æ–≤–µ–Ω—å 2: –≠–≤—Ä–∏—Å—Ç–∏–∫–∏ (fallback)

    # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
    self.alignment_stats = {
        'total_pairs': 0,
        'llm_analyzed': 0,
        'heuristic_analyzed': 0,
        'equivalent': 0,
        'refines': 0,
        'extends': 0,
        'contradicts': 0,
        'independent': 0
    }
```

**7.3.2. –ú–µ—Ç–æ–¥ _determine_relation_with_llm:**
```python
def _determine_relation_with_llm(self, text_a, text_b, claim_a, claim_b):
    # –§–æ—Ä–º–∏—Ä—É–µ–º Concise CoT –ø—Ä–æ–º–ø—Ç
    prompt = f"""–û–ø—Ä–µ–¥–µ–ª–∏ —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–æ–µ –æ—Ç–Ω–æ—à–µ–Ω–∏–µ –º–µ–∂–¥—É –¥–≤—É–º—è —É—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏—è–º–∏.
–ò—Å–ø–æ–ª—å–∑—É–π –∫—Ä–∞—Ç–∫—É—é —Ü–µ–ø–æ—á–∫—É —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏–π.

–£—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏–µ A: {text_a}

–£—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏–µ B: {text_b}

–î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–π –∫–æ–Ω—Ç–µ–∫—Å—Ç:
- –§–∞–∫—Ç—ã A: {claim_a.get('facts', '–Ω–µ—Ç')}
- –§–∞–∫—Ç—ã B: {claim_b.get('facts', '–Ω–µ—Ç')}
- –£—Å–ª–æ–≤–∏—è A: {self._format_scope(claim_a)}
- –£—Å–ª–æ–≤–∏—è B: {self._format_scope(claim_b)}

–¢–∏–ø—ã –æ—Ç–Ω–æ—à–µ–Ω–∏–π:
- equivalent: –≤—ã—Ä–∞–∂–∞—é—Ç –æ–¥–Ω–æ –∏ —Ç–æ –∂–µ (—Å–∏–Ω–æ–Ω–∏–º—ã, –ø–µ—Ä–µ—Ñ—Ä–∞–∑–∏—Ä–æ–≤–∫–∏)
- refines: –æ–¥–Ω–æ —É—Ç–æ—á–Ω—è–µ—Ç –¥—Ä—É–≥–æ–µ (–¥–æ–±–∞–≤–ª—è–µ—Ç –¥–µ—Ç–∞–ª–∏)
- extends: –¥–æ–ø–æ–ª–Ω—è—é—Ç –¥—Ä—É–≥ –¥—Ä—É–≥–∞ (—Ä–∞–∑–Ω—ã–µ –∞—Å–ø–µ–∫—Ç—ã)
- contradicts: –ø—Ä–æ—Ç–∏–≤–æ—Ä–µ—á–∞—Ç –¥—Ä—É–≥ –¥—Ä—É–≥—É
- independent: –Ω–µ —Å–≤—è–∑–∞–Ω—ã –ø–æ —Å–º—ã—Å–ª—É

–†–∞—Å—Å—É–∂–¥–µ–Ω–∏–µ (2-3 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è):
1. –ß—Ç–æ –æ–±—â–µ–≥–æ –º–µ–∂–¥—É —É—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏—è–º–∏?
2. –í —á–µ–º –∫–ª—é—á–µ–≤–æ–µ —Ä–∞–∑–ª–∏—á–∏–µ?
3. –ö–∞–∫–æ–µ –æ—Ç–Ω–æ—à–µ–Ω–∏–µ —ç—Ç–æ –æ–∑–Ω–∞—á–∞–µ—Ç?

–û—Ç–≤–µ—Ç (–æ–¥–Ω–æ —Å–ª–æ–≤–æ): [equivalent/refines/extends/contradicts/independent]"""

    response = self.llm.generate(prompt, temperature=0.2, max_tokens=300)

    relation = self._parse_relation_from_llm(response.text)

    return relation
```

**–ü–æ—á–µ–º—É —Ç–∞–∫–æ–π –ø—Ä–æ–º–ø—Ç:**
1. **Structured reasoning:** –Ø–≤–Ω–æ –ø—Ä–æ—Å–∏–º 3 —à–∞–≥–∞ —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏—è
2. **Explicit types:** –ü–µ—Ä–µ—á–∏—Å–ª—è–µ–º –≤—Å–µ –≤–æ–∑–º–æ–∂–Ω—ã–µ —Ç–∏–ø—ã —Å –ø—Ä–∏–º–µ—Ä–∞–º–∏
3. **Context inclusion:** –í–∫–ª—é—á–∞–µ–º —Ñ–∞–∫—Ç—ã –∏ —É—Å–ª–æ–≤–∏—è –¥–ª—è —Ç–æ—á–Ω–æ—Å—Ç–∏
4. **Single word answer:** –õ–µ–≥–∫–æ –ø–∞—Ä—Å–∏—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç
5. **Low temperature (0.2):** –ë–æ–ª–µ–µ –¥–µ—Ç–µ—Ä–º–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã

**7.3.3. –ú–µ—Ç–æ–¥ _parse_relation_from_llm:**
```python
def _parse_relation_from_llm(self, llm_response):
    response_lower = llm_response.lower()

    # –ò—â–µ–º –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞ –≤ –ø–æ—Ä—è–¥–∫–µ –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç–∞
    if 'equivalent' in response_lower:
        return 'equivalent'
    elif 'contradict' in response_lower:
        return 'contradicts'
    elif 'refine' in response_lower:
        return 'refines'
    elif 'extend' in response_lower:
        return 'extends'
    elif 'independent' in response_lower:
        return 'independent'

    # –ï—Å–ª–∏ –Ω–µ –Ω–∞—à–ª–∏, —Å–º–æ—Ç—Ä–∏–º –ø–æ—Å–ª–µ–¥–Ω—é—é —Å—Ç—Ä–æ–∫—É
    last_line = llm_response.strip().split('\n')[-1].lower()
    for relation in ['equivalent', 'contradicts', ...]:
        if relation in last_line:
            return relation

    # Fallback
    return 'independent'
```

**Robust parsing:**
- –°–Ω–∞—á–∞–ª–∞ –∏—â–µ–º –ø–æ –≤—Å–µ–º—É —Ç–µ–∫—Å—Ç—É
- –ó–∞—Ç–µ–º –ø—Ä–æ–≤–µ—Ä—è–µ–º –ø–æ—Å–ª–µ–¥–Ω—é—é —Å—Ç—Ä–æ–∫—É (–≥–¥–µ –æ–±—ã—á–Ω–æ –æ—Ç–≤–µ—Ç)
- Fallback –Ω–∞ 'independent' (—Å–∞–º—ã–π –±–µ–∑–æ–ø–∞—Å–Ω—ã–π)

### 7.4. –°—Ä–∞–≤–Ω–µ–Ω–∏–µ: –î–û vs –ü–û–°–õ–ï

#### –î–û (Jaccard):

```python
# –ü—Ä–∏–º–µ—Ä 1: –°–∏–Ω–æ–Ω–∏–º—ã
A: "–ë–æ–ª—å—à–æ–π –¥–æ–º"
B: "–û–≥—Ä–æ–º–Ω–æ–µ –∑–¥–∞–Ω–∏–µ"

Jaccard = 0.0 (–Ω–µ—Ç –æ–±—â–∏—Ö —Å–ª–æ–≤)
‚Üí independent ‚ùå –ù–ï–ü–†–ê–í–ò–õ–¨–ù–û
```

```python
# –ü—Ä–∏–º–µ—Ä 2: –û–¥–∏–Ω–∞–∫–æ–≤—ã–µ —Å–ª–æ–≤–∞, —Ä–∞–∑–Ω—ã–π —Å–º—ã—Å–ª
A: "–ë–∞–Ω–∫ –Ω–∞ –±–µ—Ä–µ–≥—É —Ä–µ–∫–∏"
B: "–ë–∞–Ω–∫ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª—è–µ—Ç –∫—Ä–µ–¥–∏—Ç—ã"

Jaccard = 0.33 (—Å–ª–æ–≤–æ "–±–∞–Ω–∫" –æ–±—â–µ–µ)
‚Üí extends ‚ùå –ù–ï–ü–†–ê–í–ò–õ–¨–ù–û
```

#### –ü–û–°–õ–ï (LLM + CoT):

```python
# –ü—Ä–∏–º–µ—Ä 1: –°–∏–Ω–æ–Ω–∏–º—ã
A: "–ë–æ–ª—å—à–æ–π –¥–æ–º"
B: "–û–≥—Ä–æ–º–Ω–æ–µ –∑–¥–∞–Ω–∏–µ"

LLM —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏–µ:
1. –û–±—â–µ–µ: –æ–±–∞ –æ –∫—Ä—É–ø–Ω–æ–º —Å—Ç—Ä–æ–µ–Ω–∏–∏
2. –†–∞–∑–ª–∏—á–∏–µ: —Å–∏–Ω–æ–Ω–∏–º—ã (–±–æ–ª—å—à–æ–π/–æ–≥—Ä–æ–º–Ω—ã–π, –¥–æ–º/–∑–¥–∞–Ω–∏–µ)
3. –û—Ç–Ω–æ—à–µ–Ω–∏–µ: —ç–∫–≤–∏–≤–∞–ª–µ–Ω—Ç–Ω—ã

‚Üí equivalent ‚úÖ –ü–†–ê–í–ò–õ–¨–ù–û
```

```python
# –ü—Ä–∏–º–µ—Ä 2: –û–¥–∏–Ω–∞–∫–æ–≤—ã–µ —Å–ª–æ–≤–∞, —Ä–∞–∑–Ω—ã–π —Å–º—ã—Å–ª
A: "–ë–∞–Ω–∫ –Ω–∞ –±–µ—Ä–µ–≥—É —Ä–µ–∫–∏"
B: "–ë–∞–Ω–∫ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª—è–µ—Ç –∫—Ä–µ–¥–∏—Ç—ã"

LLM —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏–µ:
1. –û–±—â–µ–µ: —Å–ª–æ–≤–æ "–±–∞–Ω–∫"
2. –†–∞–∑–ª–∏—á–∏–µ: –æ–¥–∏–Ω –æ –≥–µ–æ–≥—Ä–∞—Ñ–∏–∏ (–±–µ—Ä–µ–≥), –¥—Ä—É–≥–æ–π –æ —Ñ–∏–Ω–∞–Ω—Å–∞—Ö (–∫—Ä–µ–¥–∏—Ç—ã)
3. –û—Ç–Ω–æ—à–µ–Ω–∏–µ: —Ä–∞–∑–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è —Å–ª–æ–≤–∞, –Ω–µ —Å–≤—è–∑–∞–Ω—ã

‚Üí independent ‚úÖ –ü–†–ê–í–ò–õ–¨–ù–û
```

### 7.5. –ú–µ—Ç—Ä–∏–∫–∏ —É–ª—É—á—à–µ–Ω–∏—è

| –ú–µ—Ç—Ä–∏–∫–∞ | –î–û (Jaccard) | –ü–û–°–õ–ï (LLM + CoT) |
|---------|--------------|-------------------|
| –¢–æ—á–Ω–æ—Å—Ç—å –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –æ—Ç–Ω–æ—à–µ–Ω–∏–π | ~55-60% | **~85-90%** |
| –ü–æ–Ω–∏–º–∞–Ω–∏–µ —Å–∏–Ω–æ–Ω–∏–º–æ–≤ | ‚ùå –ù–µ—Ç | ‚úÖ –î–∞ |
| –ü–æ–Ω–∏–º–∞–Ω–∏–µ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ | ‚ùå –ù–µ—Ç | ‚úÖ –î–∞ |
| –†–∞–∑–ª–∏—á–µ–Ω–∏–µ –æ–º–æ–Ω–∏–º–æ–≤ | ‚ùå –ù–µ—Ç | ‚úÖ –î–∞ |
| –£—á–µ—Ç scope/—É—Å–ª–æ–≤–∏–π | ‚ö†Ô∏è –ß–∞—Å—Ç–∏—á–Ω–æ | ‚úÖ –ü–æ–ª–Ω–æ—Å—Ç—å—é |
| False positives (contradicts) | ~25% | **~5%** |
| Cost per pair | $0 | ~$0.01-0.02 |
| Latency per pair | ~5ms | ~1-2 seconds |

### 7.6. –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –∏ –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥

**–ù–æ–≤—ã–π –º–µ—Ç–æ–¥ get_alignment_stats:**
```python
def get_alignment_stats(self):
    stats = self.alignment_stats.copy()

    total = stats['total_pairs']
    if total > 0:
        stats['llm_pct'] = (stats['llm_analyzed'] / total) * 100
        stats['heuristic_pct'] = (stats['heuristic_analyzed'] / total) * 100

        # –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –æ—Ç–Ω–æ—à–µ–Ω–∏–π
        stats['equivalent_pct'] = (stats['equivalent'] / total) * 100
        stats['refines_pct'] = (stats['refines'] / total) * 100
        stats['extends_pct'] = (stats['extends'] / total) * 100
        stats['contradicts_pct'] = (stats['contradicts'] / total) * 100
        stats['independent_pct'] = (stats['independent'] / total) * 100

    stats['mode'] = 'LLM + Concise CoT + Heuristics'

    return stats
```

**–ß—Ç–æ –æ—Ç—Å–ª–µ–∂–∏–≤–∞–µ—Ç—Å—è:**
- –°–∫–æ–ª—å–∫–æ –ø–∞—Ä –ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–æ —á–µ—Ä–µ–∑ LLM vs —ç–≤—Ä–∏—Å—Ç–∏–∫–∏
- –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Ç–∏–ø–æ–≤ –æ—Ç–Ω–æ—à–µ–Ω–∏–π
- –†–µ–∂–∏–º —Ä–∞–±–æ—Ç—ã –∞–≥–µ–Ω—Ç–∞

### 7.7. –§–∞–π–ª—ã –∏–∑–º–µ–Ω–µ–Ω—ã

**–ò–∑–º–µ–Ω–µ–Ω–Ω—ã–µ —Ñ–∞–π–ª—ã:**
- `src/agents/aligner.py`:
  - –î–æ–±–∞–≤–ª–µ–Ω—ã –∏–º–ø–æ—Ä—Ç—ã LLM (—Å—Ç—Ä–æ–∫–∏ 15-26)
  - –†–∞—Å—à–∏—Ä–µ–Ω __init__ —Å LLM –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏ (—Å—Ç—Ä–æ–∫–∏ 32-79)
  - –û–±–Ω–æ–≤–ª–µ–Ω process –¥–ª—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ (—Å—Ç—Ä–æ–∫–∏ 81-128)
  - –û–±–Ω–æ–≤–ª–µ–Ω _determine_relation —Å 2-level strategy (—Å—Ç—Ä–æ–∫–∏ 167-199)
  - –î–æ–±–∞–≤–ª–µ–Ω _determine_relation_with_llm + Concise CoT (—Å—Ç—Ä–æ–∫–∏ 201-255)
  - –î–æ–±–∞–≤–ª–µ–Ω _determine_relation_with_heuristics (—Å—Ç—Ä–æ–∫–∏ 257-307)
  - –î–æ–±–∞–≤–ª–µ–Ω _format_scope (—Å—Ç—Ä–æ–∫–∏ 309-327)
  - –î–æ–±–∞–≤–ª–µ–Ω _parse_relation_from_llm (—Å—Ç—Ä–æ–∫–∏ 329-362)
  - –î–æ–±–∞–≤–ª–µ–Ω get_alignment_stats (—Å—Ç—Ä–æ–∫–∏ 629-656)

**–ü–æ—á–µ–º—É –∏–º–µ–Ω–Ω–æ —Ç–∞–∫–∞—è —Å—Ç—Ä—É–∫—Ç—É—Ä–∞:**
1. **–ú–æ–¥—É–ª—å–Ω–æ—Å—Ç—å:** –û—Ç–¥–µ–ª—å–Ω—ã–µ –º–µ—Ç–æ–¥—ã –¥–ª—è LLM –∏ —ç–≤—Ä–∏—Å—Ç–∏–∫
2. **–¢–µ—Å—Ç–∏—Ä—É–µ–º–æ—Å—Ç—å:** –ú–æ–∂–Ω–æ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞—Ç—å –∫–∞–∂–¥—ã–π –º–µ—Ç–æ–¥ –æ—Ç–¥–µ–ª—å–Ω–æ
3. **Fallback:** Graceful degradation –Ω–∞ —ç–≤—Ä–∏—Å—Ç–∏–∫–∏
4. **Observability:** –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –¥–ª—è debugging

### 7.8. –ü—Ä–µ–∏–º—É—â–µ—Å—Ç–≤–∞ Concise CoT vs –ø–æ–ª–Ω—ã–π CoT

| –•–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∞ | –ü–æ–ª–Ω—ã–π CoT | Concise CoT |
|----------------|------------|-------------|
| –¢–æ–∫–µ–Ω–æ–≤ –≤ –ø—Ä–æ–º–ø—Ç–µ | ~500-800 | ~200-300 |
| –¢–æ–∫–µ–Ω–æ–≤ –≤ –æ—Ç–≤–µ—Ç–µ | ~300-500 | ~100-150 |
| Cost per request | ~$0.03 | **~$0.01** |
| Latency | ~3-5 sec | **~1-2 sec** |
| Accuracy | ~90% | ~85-90% |
| –õ–µ–≥–∫–æ—Å—Ç—å –ø–∞—Ä—Å–∏–Ω–≥–∞ | ‚ö†Ô∏è –°—Ä–µ–¥–Ω–µ | ‚úÖ –õ–µ–≥–∫–æ |

**–í—ã–≤–æ–¥:** Concise CoT –¥–∞–µ—Ç 85-90% —Ç–æ—á–Ω–æ—Å—Ç–∏ –ø–æ–ª–Ω–æ–≥–æ CoT –ø—Ä–∏ 3x –º–µ–Ω—å—à–µ–π —Å—Ç–æ–∏–º–æ—Å—Ç–∏.

### 7.9. –ö–∞–∫ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å

```python
# –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∞—è –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è (—Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è)
aligner = AlignerAgent()
updated_pairs, conflicts = aligner.process(pairs, claims)

# –¢–æ–ª—å–∫–æ LLM
aligner = AlignerAgent(use_llm=True)
updated_pairs, conflicts = aligner.process(pairs, claims)

# –¢–æ–ª—å–∫–æ —ç–≤—Ä–∏—Å—Ç–∏–∫–∏ (–±—ã—Å—Ç—Ä–æ, –Ω–æ –º–µ–Ω–µ–µ —Ç–æ—á–Ω–æ)
aligner = AlignerAgent(use_llm=False)
updated_pairs, conflicts = aligner.process(pairs, claims)

# –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
stats = aligner.get_alignment_stats()
print(f"LLM –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω: {stats['llm_pct']:.1f}%")
print(f"Contradicts: {stats['contradicts_pct']:.1f}%")
```

---

