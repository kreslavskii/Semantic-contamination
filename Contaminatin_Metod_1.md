# Инструкция по сравнению и слиянию текстов (GPT-5 Thinking)

## Введение

Данный проект предназначен для **сравнения и слияния до четырёх текстов на общую тему** с различной структурой, с использованием возможностей модели GPT-5 (на примере ChatGPT). Процесс разбивается на последовательные этапы обработки, каждый из которых выполняется отдельной ролью (агентом) с чётко заданным шаблоном запроса. **Цель** – получить единый согласованный ответ, который объединяет информацию из всех исходных документов, обеспечивая корректность фактов, полноту, логическую связность и проверяемость утверждений. Подход опирается на современные методы: парное сравнение ответов с LLM-судьёй (LLM-as-a-Judge) для более устойчивой оценки качества по сравнению с одиночным ранжированием, многоагентные дебаты для многокритериального анализа, целевая верификация фактов через *Chain-of-Verification* (CoVe) чтобы снижать галлюцинации, а также самопроверку утверждений методом *SelfCheck* для выявления неустойчивых фактов.

**Глобальные принципы:** Работа ведётся строго с содержанием предоставленных текстов и надёжными внешними источниками для факт-чека – никаких домыслов или «галлюцинаций» модели. Каждое фактическое утверждение помечается маркером `[F#]` и должно иметь явную опору (либо в исходных документах, либо в внешних источниках). Стиль изложения на каждом этапе – информационный и нейтральный, без лишней риторики. **Единицей информации** выбран *тезис* (claim) в формате модели Тульмина: утверждение с указанием основания (доказательства), границ применимости и помеченных фактов. Благодаря декомпозиции текстов на тезисы, сравнение ведётся не между целыми документами, а между **отдельными утверждениями** и их обоснованиями, что повышает гранулярность и точность слияния. Ниже описаны шаги работы, артефакты (табличные файлы) и шаблоны команд для каждого этапа, а также рекомендации по оркестрации процесса.

## Шаг 1: Экстракция тезисов (Extractor)

**Вход:** Исходные документы в формате Markdown (например, `A.md`, `B.md`, ... до четырех файлов).  
**Выход:** Таблица тезисов `claims.tsv` (черновой вариант).

На первом этапе из каждого исходного текста извлекаются ключевые содержательные утверждения – тезисы. Необходимо проигнорировать вводные рассуждения, метафоры, примеры без доказательной ценности и прочий «шум», сосредоточившись на фактах, выводах и аргументах текста. Каждый выявленный тезис оформляется в виде строки таблицы с следующими полями:

- `id` – уникальный идентификатор тезиса (например, C001, C002…)
- `claim` – формулировка основного утверждения тезиса
- `evidence_inline` – краткое упоминание доказательства или источника внутри текста (если присутствует)
- `scope.time` / `scope.jurisdiction` / `scope.conditions` – контекст применения: время, юрисдикция/область, специальные условия (заполняется, если явно указано или ограничено в тезисе)
- `facts` – список фактических атомов, содержащихся в тезисе, помеченных как F1, F2, … (например, конкретные числа, даты, имена собственные, упоминания исследований)
- `origin` – источник тезиса: указание из какого документа и какого места (например, документ A, раздел 2 или абзац 3)
- `notes` – примечания (например, если тезис сокращён или перефразирован для ясности)

**Пример промпта Extractor:** (запрос модельной роли для извлечения тезисов)

> Ты – **Экстрактор**. Извлеки содержательные тезисы из каждого документа. Игнорируй вводные части, примеры и метафоры без доказательной функции. Для каждого тезиса оформи карточку:  
> `id | claim | evidence_inline | scope.time | scope.jurisdiction | scope.conditions | facts | origin | notes`  
> Где `facts` – список маркеров `F1; F2; …` для фактических элементов. В поле `origin` укажи документ и ориентир (раздел или абзац). **Не добавляй информацию извне и не обобщай** – работай только с текстом документа.

После выполнения этого шага на выходе формируется черновой файл `claims.tsv`, содержащий все тезисы из документов. Следует убедиться, что тезисы охватывают **все существенные моменты исходных текстов** (полнота) и не содержат риторических или вводных фраз. Если какие-то факты или условия применимости явно указаны в тексте, они должны быть вынесены в соответствующие поля тезиса. Шаг полностью автоматизируется – достаточно выполнить указанный промпт для каждого документа по очереди, либо сразу для всех документов, и система сгенерирует список тезисов.

## Шаг 2: Терминологическая нормализация (Normalizer)

**Вход:** Черновой `claims.tsv` (объединённый список тезисов из всех документов).  
**Выход:** Обновлённый `claims.tsv` (нормализованный) и таблица терминов `term_map.tsv`.

На этом этапе приводится к единому стандарту вся терминология, используемая в тезисах. Это важно при сравнении, поскольку одно и то же понятие может быть названо по-разному в разных текстах (синонимы, сокращения, переводы и кальки). **Normalizer** должен выявить повторяющиеся термины и заменить их на каноничные формы, составив словарь соответствия.

Выполняются следующие задачи:  
- Для каждого термина, встретившегося в `claim` тезисов, выбирается **каноническая лемма** (например, самый распространённый или официальный вариант названия).  
- Составляется таблица `term_map.tsv` со столбцами: `canonical | variants | lang | definition_source | notes`. В поле `variants` перечисляются обнаруженные варианты этого термина (включая буквальные кальки, переводы на другие языки, аббревиатуры и т.п.), `lang` фиксирует язык/происхождение термина, `definition_source` – при необходимости источник определения или ссылку на стандарт, а `notes` – прочие комментарии.  
- В самом `claims.tsv` в каждом тезисе поле `claim` переписывается так, чтобы вместо разных вариантов использовался только выбранный **канонический** вариант терминологии. Все замены термина (алиасы) можно указать в `notes` для сохранения информации.  
- Единицы измерения, форматы дат, величины – также унифицируются по стандартам (желательно использовать единицы СИ, ISO-форматы дат и т.д., если тексты изначально их не совпадали).  
- Типы сущностей могут быть отмечены для справки (например, отметить, что термин – это организация, метрика, географическое название, процедура и т.п.).

**Пример промпта Normalizer:**

> Ты – **Нормализатор терминологии**. Проанализируй список тезисов и унифицируй термины: составь `term_map.tsv` со столбцами `canonical | variants | lang | definition_source | notes`. Для каждого термина подбери каноническую форму (лемму) и перечисли его алиасы (включая кальки и многоязычные эквиваленты). Затем обнови каждое `claim` в `claims.tsv`, заменив термины на их `canonical`-формы. Алиасы перечисли в поле `notes`. Также унифицируй единицы измерения (до SI) и формат дат (ISO). Убедись, что значения тезисов не исказились при такой замене и что поля `scope` (время, регион) тоже приведены к единому формату.

После этого шага тезисы в `claims.tsv` будут использовать единый терминологический язык, что облегчает их прямое сравнение. **Важно:** не допускать смысловых сдвигов при нормализации – термин должен сохранять своё значение. Все термины должны иметь определённый канонический эквивалент и перечисленные варианты, даже если встречаются в разных языках. Этот шаг полностью автоматизируем: модель по заданному шаблону сама сформирует словарь терминов и обновит тезисы.

## Шаг 3: Формирование пар тезисов для сравнения (Blocking)

**Вход:** Нормализованный `claims.tsv` и `term_map.tsv`.  
**Выход:** Список пар-кандидатов `pairs.tsv` для сопоставления тезисов.

Теперь необходимо определить, какие тезисы из разных документов **имеют отношение к одной и той же теме или факту** и должны быть напрямую сравнены. Поскольку из разных источников тезисы могут выражать схожие идеи, мы формируем множество пар A–B, которые потенциально стоит сравнить (этот процесс часто называется *blocking* – отбор кандидатов для последующего сопоставления).

Критерии отбора пар задаются таким образом, чтобы не пропустить возможные соответствия:  
- Пара тезисов включается, если **есть хотя бы один общий термин** или упомянутая сущность в их тексте (после нормализации терминологии). Совпадение по каноническому термину указывает на общую тему.  
- Либо если пересекаются их поля `scope` – например, они явно относятся к одному и тому же временному периоду или юрисдикции.  
- Либо если в обоих тезисах упомянута одна и та же **метрика или единица измерения**, что может говорить о сравнении одних показателей.

Каждая такая пара заносится в таблицу `pairs.tsv` с полями: `pair_id` (уникальный идентификатор пары), `A_id` и `B_id` (идентификаторы сравниваемых тезисов), `matched_keys` (указание, какие ключи/термины совпали), `scope_overlap` (описание пересечения по условиям, если есть) и `comments` (дополнительные заметки, например, уверенность в релевантности пары).

**Пример промпта Blocking:**

> Ты – **Агент сопоставления кандидатов**. Сформируй все пары тезисов из `claims.tsv`, которые потенциально относятся к одной теме. Учитывай совпадения по ключевым элементам: (i) хотя бы один общий канонический термин или сущность; (ii) пересечение во времени (`scope.time`) или общая юрисдикция; (iii) совпадение упомянутой метрики или единиц измерения. Для каждой найденной пары выведи строку в `pairs.tsv` формата:  
> `pair_id | A_id | B_id | matched_keys | scope_overlap | comments`.  
> Стремись к тому, чтобы охватить максимум релевантных пар (лучше включить лишние, чем пропустить важные).

Результатом станет таблица кандидатов `pairs.tsv`. На этом этапе допускается избыточность (может быть предложено больше пар, чем действительно значимо) – важнее обеспечить **полный охват** всех потенциальных пересечений тематики, чтобы на следующем шаге ничего не упустить. Шаг автоматизирован; однако, при желании, пользователь может просмотреть список пар и отфильтровать явно нерелевантные связи, прежде чем двигаться дальше.

## Шаг 4: Семантическое сопоставление и типизация отношений (Aligner/NLI)

**Вход:** `pairs.tsv` (список пар кандидатов) и исходный `claims.tsv` (для содержания тезисов).  
**Выход:** Обновлённый `pairs.tsv` с помеченными отношениями между тезисами; файл `conflicts.md` (список выявленных противоречий).

На этом этапе каждая пара тезисов A и B анализируется более глубоко, чтобы определить **характер их отношения**. Это своего рода Natural Language Inference (NLI) между утверждениями: выясняем, эквивалентны ли тезисы, дополняют друг друга или противоречат. Результат позволит сгруппировать сходные тезисы и отметить конфликтующие зоны для проверки.

Для **каждой пары A/B** выполните:  
- Определите тип отношения между тезисами, выбирая из следующих категорий:  
- `equivalent` – тезисы выражают по сути одно и то же утверждение (может быть разными словами);  
- `refines` – тезис A уточняет или детализирует тезис B;  
- `extends` – тезис A дополняет новыми сведениями тезис B;  
- `contradicts` – содержание тезисов противоречит друг другу;  
- `independent` – тезисы не связаны по смыслу (говорят о разном).  
- Кратко обоснуйте выбранное отношение, **опираясь на тексты тезисов A и B**. В обосновании хорошо привести короткие цитаты или факты из обоих тезисов (например, указать идентификаторы A_id/B_id и фразы из `claim`), чтобы было понятно, откуда сделан вывод.  
- Дополнительно оцените логико-семантический статус пары в терминах вывода (NLI): указывает ли один тезис на вывод из другого (`entails`), противоречит ли (`contradicts`) или нейтрален (`neutral`). Если есть явное причинно-следственное или логическое несоответствие, отметьте и причину.  
- Если категория отношения – `contradicts`, необходимо классифицировать, **что это за конфликт**: - исти́нный конфликт – тезисы противоречат друг другу, *и при этом говорят об одном и том же в тех же условиях (время, место)*; - кажущийся конфликт – противоречие только на первый взгляд, потому что тезисы имеют разные условия применимости, определения или контексты (то есть говорят о разном под разными предпосылками); - псевдоконфликт – различие лишь в формулировках или терминологии, фактически противоречия нет (разночтение лексическое).  
- Все конфликтующие пары выпишите дополнительно в файл `conflicts.md` с пояснениями, в чём суть противоречия и какой тип (из трёх выше) присвоен.

Обновите запись данной пары в `pairs.tsv`, добавив поля отношения. Формат дополняется колонками: `relation | ``nli`` | rationale | ``conflict_type`` | ``condition_notes`. Здесь `relation` – один из пяти типов связи, `nli` – логический статус (entails/contradicts/neutral), `rationale` – ваше краткое обоснование, `conflict_type` – вид конфликта (для противоречий), `condition_notes` – заметки об условиях (например, если связь справедлива только при определённых обстоятельствах, их указать).

**Пример промпта Aligner/NLI:**

> Ты – **Аналитик тезисов (Aligner)**. Для каждой пары тезисов A и B из списка: определи их отношение (`equivalent | refines | extends | contradicts | independent`). Аргументируй в 1–2 предложениях на основе содержания A и B – укажи, какие части утверждений совпадают или различаются. Если обнаружено противоречие, уточни его характер: это истиное противоречие (одна и та же область/время) или кажущееся (разные условия или разные понятия) или просто лексическая разница. Также укажи логический вывод: следует ли один тезис из другого, противоречит или нейтрально. Обнови запись пары формата:  
> `pair_id`` | ... | relation | ``nli`` | rationale | ``conflict_type`` | ``condition_notes`.  
> Все выявленные противоречия сгруппируй в отдельном файле `conflicts.md` с коротким описанием каждой конфликтной точки.

После этого шага мы получим две вещи: полноту информации о каждой паре (как они соотносятся) в `pairs.tsv` и список конфликтных мест в `conflicts.md`. **Автоматизация:** данный шаг может выполняться моделью по шаблону, но требует внимательного анализа текста. **Критично**, чтобы обоснование опиралось на реальные цитаты из A и B – это позволяет в дальнейшем проверить достоверность отношений. Правильная классификация конфликтов важна для последующей их обработки: истинные противоречия нужно будет обязательно разрешить (через проверку или выбор позиции), кажущиеся – явно развести по условиям, псевдо – устранить через унификацию формулировок.

## Шаг 5: Слепое парное судейство по критериям (Judge)

**Вход:** Отобранные пары тезисов (особенно пары с отношением `equivalent/refines/extends/contradicts` из `pairs.tsv`) вместе с текстами этих тезисов или их исходных фрагментов.  
**Выход:** Результаты судейства `judgments.tsv` – для каждой пары решение, какой тезис лучше по заданным критериям, с отметками по каждому критерию.

После структурного сопоставления тезисов проводится **качественное сравнение содержательного качества** двух вариантов ответа (тезис A против тезиса B) по ряду критериев. Эта стадия имитирует соревнование ответов и применяется, когда у нас есть альтернативные формулировки одной идеи или разных подходов к вопросу.

Критерии оценки (могут быть скорректированы под задачу, здесь основные):  
- **C1: Корректность фактов и непротиворечивость.** Насколько тезис фактически правильный, нет ли ошибок или внутренних противоречий.  
- **C2: Полнота ответа по вопросу.** Насколько тезис охватывает все существенные аспекты поставленного вопроса или темы.  
- **C3: Логическая связность.** Ясна ли структура аргумента, нет ли скрытых непроверенных допущений, вытекает ли вывод из оснований.  
- **C4: Экономия языка.** Насколько тезис кратко и по делу сформулирован, без лишней «воды», сохраняя всю суть.  
- **C5: Проверяемость и источники.** Подкреплён ли тезис фактами, ссылками на источники, и можно ли проверить изложенные сведения.

**Judge** получает на вход два тезиса (A и B) **без указания их происхождения** (чтобы не было biais на источник). Оркестратор на этом этапе должен обеспечить *слепое судейство*: анонимизировать варианты, назвав их, например, **Кандидат-1 и Кандидат-2**, а также **рандомизировать порядок** их подачи. Это важно для устранения позиционного эффекта (модель может склоняться к тому, что идёт первым, если не перемешивать). Судья рассматривает только содержимое тезисов, **игнорируя стиль, длину изложения или другие метаданные**.

Для каждой пары генерируется сравнение: по каждому критерию выносится локальное решение, и затем итоговый вердикт, какой тезис лучше либо что они равны. Формат `judgments.tsv`: `pair_id | winner | C1 | C2 | C3 | C4 | C5 | notes` (если используем 5 критериев; в случае 4 критериев – без C5). В столбцах C1…C5 проставляется, условно, +/– (или да/нет) в пользу каждого кандидата по данному критерию, *либо* можно дать короткий комментарий. В `winner` отмечается итог: `A` лучше, `B` лучше, либо `tie` (ничья). В `notes` фиксируются важные замечания или обоснование выбора.

**Пример промпта Judge (для одного сравнения):** (формулируется *буквально*, как системная инструкция судье)

> Ты – **Судья**. Тебе даны два ответа (тезиса) на одну тему – назовём их Кандидат-1 и Кандидат-2 (порядок случайный). Сравни их **только по содержанию** – стиль, длину и прочее игнорируй. Оцени по критериям (ответь «да» или «нет» по каждому, с коротким объяснением в одну строку):  
> **C1:** корректность фактов и отсутствие противоречий;  
> **C2:** полнота ответа по вопросу;  
> **C3:** логическая связность аргументации;  
> **C4:** экономия языка (нет лишнего);  
> **C5:** проверяемость – наличие фактов и ссылок.  
> Затем вынеси итог: `Кандидат-1 лучше | Кандидат-2 лучше | ничья` – с кратким объяснением опираясь на критерии. Не упоминай никаких метаданных и не гадай об источниках.

Выполнять такой сравнительный анализ должен один и тот же агент (модель) по всем парам, чтобы оценки были сопоставимы. Обязательно провести **двойной прогон** для каждой существенной пары: сперва в порядке (A vs B), затем поменять местами (B vs A) и снова оценить. Это помогает выявить нестабильность суждений и позиционные смещения модели. Если результаты двух прогонов расходятся, оркестратор может зафиксировать это как неопределённость или организовать дополнительный раунд с уточнёнными критериями.

В итоге формируется таблица `judgments.tsv`. Например:

    pair_id | winner | C1 | C2 | C3 | C4 | C5 | notes
    P007    | A      | A+ | tie| A+ | B+ | A+ | Оба ответа корректны, но А приводил больше фактов и лаконичнее изложен...

Здесь в критериях можно указывать, кто лидирует: например, `A+` если A лучше по критерию, `B+` если B, `tie` если паритет. **Оркестратор** суммирует все оценки: если по разным критериям победители разнятся, можно использовать правила агрегирования (напр. большинство критериев, или приоритетным считать корректность). В случае ничьей – сохранить оба варианта для возможного слияния (Pareto-фронт).

*Автоматизация:* вынесение суждений по критериям можно поручить модели, однако требуется вмешательство человека/оркестратора для: а) перемешивания и анонимизации вариантов перед каждой оценкой, б) запуска второй оценки с инверсией ролей, в) принятия решения при противоречивых исходах или ничье. Это полуавтоматический этап.

## Шаг 6: Фактчекинг через веб-поиск (Verifier, CoVe)

**Вход:** Спорные утверждения и конфликтующие тезисы (например, все пары, помеченные как `contradicts`, а также тезисы, вызвавшие сомнения на предыдущих шагах – отмеченные как `uncertain` или где судья дал неоднозначные оценки). Также список фактов `[F#]` из этих тезисов.  
**Выход:** Таблица проверки фактов `evidence.tsv` – результаты поиска внешних источников по ключевым вопросам.

Этот этап предназначен для **независимой проверки фактических утверждений** с помощью внешних надёжных источников. Реализуется стратегия *Chain-of-Verification*: сперва формулируются целевые вопросы к наиболее уязвимым фактам, затем ищутся ответы (источники), и на основе этого уточняется статус утверждений.

Процедура: - Составьте перечень конкретных вопросов (обычно 3–7 на кластер спорных тезисов) для проверки ключевых фактов. Каждый вопрос должен фокусироваться на одном утверждении или детали, вызывающей сомнение. Например, если два тезиса противоречат в числах или датах, вопрос может быть: «Какое значение показателя X за год Y согласно \[авторитетному источнику\]?». Вопросы должны быть сформулированы так, чтобы на них можно было найти ответ в источниках (в интернете, базе знаний и пр.). - Для **каждого вопроса** выполните поиск в надежных источниках. Приоритизируйте **иерархию авторитетности**: сперва официальные и рецензируемые публикации (научные статьи, отчёты), затем качественные препринты или отчёты, затем статьи экспертов и признанные базы знаний. По возможности используйте не менее одного первичного источника (например, научный журнал или официальный документ) или два независимых вторичных источника для каждого факта. - Найдите ответ и выпишите его в `evidence.tsv` строкой с полями: `claim_id`` | ``question`` | status | source | date | quote`. - `claim_id` – идентификатор тезиса/факта, к которому относится вопрос. - `question` – сформулированный поисковый запрос/вопрос. - `status` – результат проверки: `supported` (подтверждается источником), `refuted` (опровергается), либо `uncertain` (нет однозначного ответа или противоречивые данные). Если факт условно верен только при определённых условиях, можно отметить как `conditional` (это разновидность supported, но с оговоркой). - `source` – название или краткое описание источника + URL. Например, журнал и DOI, или сайт и заголовок статьи. - `date` – дата публикации или последнего обновления источника. - `quote` – короткая цитата (до ~30 слов) из источника, которая отвечает на вопрос. **Важно** выбирать цитаты, непосредственно подтверждающие или опровергающие факт. Если разные источники расходятся, желательно отразить это (например, сделать две записи с противоположными статусами и отметить конфликт).

**Пример промпта Verifier (CoVe):**

> Ты – **Проверяющий фактов** с доступом к веб-поиску. Составь 3–7 целевых вопросов для проверки спорных тезисов и фактов (\[F#\]). Затем по каждому вопросу найди надёжный источник и ответь. Для каждого ответа представь: `claim_id`, сам вопрос, статус (`supported/refuted/uncertain`), источник (название и URL), дата публикации, и короткую цитату (до 30 слов) из источника. Если источники расходятся между собой, явно укажи это в статусе или примечании.

Например, строка в `evidence.tsv` может выглядеть так:

    C017 | Каков уровень X в 2021 году? | refuted | WHO Report 2022 (who.int/...) | 2022-11-05 | "... уровень X в 2021 составил 5%, что противоречит данным в [источнике]."

Политика включения фактов такова, что **только подтверждённые (**`supported`**) или условно подтверждённые** факты могут пойти в финальный текст. Если статус `refuted` – тезис будет отклонён; если `uncertain` – он не должен быть утверждён без оговорок. Все собранные цитаты и источники затем могут быть использованы при написании финального ответа (для ссылок) либо отправлены в Audit.md для прозрачности.

*Автоматизация:* генерацию вопросов и даже поиск может выполнять связка моделей (например, небольшая модель с доступом к сети либо плагины ChatGPT). Можно автоматизировать составление `evidence.tsv` на основе запросов. Однако контроль пользователя полезен для оценки качества источников – предпочтительно убедиться, что выбраны действительно авторитетные данные. В реальном проекте часто делают так: LLM предлагает список вопросов и потенциальных ссылок, пользователь или скрипт выполняет поиск, затем LLM обрабатывает найденные тексты и заполняет таблицу.

## Шаг 7: SelfCheck – проверка устойчивости формулировок

**Вход:** Тезисы, не подкреплённые внешними источниками, а также тезисы, помеченные как спорные/неопределённые по предыдущим проверкам. Это могут быть отдельные утверждения из `claims.tsv` или вновь синтезированные фрагменты, требующие проверки на устойчивость.  
**Выход:** Таблица результатов самопроверки `consistency.tsv`.

Даже после внешнего фактчекинга и судейства, остаётся риск, что некоторые утверждения модель сформулировала неустойчиво – т.е. при перефразировании может «выплыть» другая информация, или модель сама противоречиво воспроизводит факт. Метод **SelfCheck** позволяет выявить такие неустойчивые места. Идея: мы несколько раз генерируем перефраз данного тезиса с теми же входными данными и сравниваем результаты. Если факты «плавают», значит исходная формулировка ненадёжна.

Алгоритм: для каждого целевого тезиса (например, из спорных или новых, не подтверждённых фактов) попросите модель сгенерировать **5 перефраз** – т.е. сказать то же самое разными словами. Затем сравните все фактуальные элементы в этих вариантах: совпадают ли числа, имена, причинно-следственные связи? Если **хотя бы один факт изменился или исчез** в какой-то версии, это признак нестабильности.

Таблица `consistency.tsv` содержит поля: `claim_id | variants_diff | unstable_facts | decision`. - `variants_diff` – заметки о различиях между вариантами (например, «В 2 из 5 перефраз изменилось число X на Y»). - `unstable_facts` – конкретные факты, которые оказались неустойчивыми (список F-меток или описаний). - `decision` – отмечаем тезис как `uncertain` (неустойчив) если выявлены расхождения, или `stable` если во всех перефразах факты一致ны.

**Пример промпта SelfCheck:**

> Ты – **Внутренний проверяющий**. Возьми следующий тезис и перефразируй его 5 раз разными словами, сохраняя смысл. Затем сравни все полученные варианты: совпадают ли все факты (числа, даты, имена, причины и следствия)? Если какой-то факт в разных вариантах звучит по-разному – перечисли эти расхождения. Пометь итогово, стабилен тезис или нет. Выведи в формате:  
> `claim_id | variants_diff | unstable_facts | decision`.

Эта операция выполняется моделью автоматически. В результате мы явно увидим, какие утверждения небезопасно брать в финальный ответ без оговорок. Например, если модель сама по-разному трактует числовой факт при перестройке фразы, велика вероятность, что исходный источник был неоднозначен или модель «галлюцинирует». **Оркестратор** может принять решение: либо исключить такой тезис, либо отправить его на дополнительную проверку (снова через фактчек, запрос пользователю, либо просто пометить как требующий подтверждения). Рекомендуется: если более 10% тезисов в тематическом кластере оказались `uncertain`, вернуться к шагам 5–6 для дополнительной проверки и только затем продолжать синтез.

## Шаг 8: Синтез финального текста (Synthesizer)

**Вход:** Все собранные артефакты: очищенный и нормализованный список тезисов (`claims.tsv`), информация о парных отношениях (`pairs.tsv`), результаты судейства (`judgments.tsv`), результаты фактчекинга (`evidence.tsv`), результаты самопроверки (`consistency.tsv`), а также карта конфликтов (`conflicts.md`).  
**Выход:** Сводный документ `Merged.md` – финальный объединённый ответ по теме, с ссылками на источники и пометками границ применимости.

На данном этапе большая модель (или тот же GPT-5) должна, наконец, **собрать воедино** всю проверенную информацию и представить её в связном тексте. Финальный ответ должен включать: общие утверждения, которые подтвердились по всем источникам (инварианты); дополнительные факты, которые есть в одних источниках и не противоречат другим (комплементы); а также учесть конфликтные моменты (либо выбрав одну из позиций, либо указав условность/неопределённость).

Правила синтеза таковы:  
- Включаются **только тезисы, статус которых** после проверок – *подтверждён* (`supported`) или условно подтверждён (`conditional`) при определённых условиях. То есть, если тезис верен не во всех случаях, в тексте это оговаривается (например: «... верно для развитых стран \[C12\]»).  
- Тезисы, получившие статус *неподтверждённых или опровергнутых* (`refuted/uncertain`), **исключаются из основного текста**. Они не выбрасываются совсем, а будут отражены в отчёте (Audit) как отклонённые или требующие дальнейшей проверки. - Если имелись истинные противоречия между источниками (по критичным вопросам), то в финальном тексте выбирается та позиция, которая подкреплена лучшими доказательствами или более проверяемая. Альтернативная позиция выносится в раздел «опровергнутое/устаревшее» либо оговаривается, что существуют разные точки зрения (с соответствующей ссылкой в Audit).  
- **Иниварианты:** Если несколько источников (тезисов) говорили об одном и том же – эти сведения должны быть объединены и представлены как единый вывод. Например, одинаковые выводы разных исследователей приводятся один раз, с указанием всех источников.  
- **Комплементы:** Если один вариант упоминал что-то ценное, чего не было в другом, и это не конфликтует с общей картиной, следует добавить это как часть ответа. То есть, берём сильные стороны каждого из исходных вариантов, чтобы обогатить итог. Это преимущество *генеративного слияния*, позволяющее получить более полный ответ, чем любой из исходников по отдельности.  
- **Разрешение конфликтов:** Различия, обусловленные разными условиями, можно включить как отдельные положения с чётким указанием условий. Например: «Для городов с населением \>1 млн, эффект X наблюдается \[C15\]; в малых городах, напротив, Y \[C16\].» Таким образом оба противоречащих тезиса могут сохраниться, но разведены по контексту (оба условно верны). Если же одно утверждение явно ложное – оно просто не включается, а отмечается в Audit.

Стилистические требования: текст пишется на **академическом русском языке** (точно и сжато), без разговорных элементов и с минимальным объемом – **«экономия языка»** сохраняется как принцип. Однако слишком телеграфный стиль исходников нужно «развернуть» до полноценной аргументации: добавить связующие фразы, объяснить вывод, чтобы читателю было понятно. Обратно, избыточно многословные места надо ужать, сохранив факты.

**Структура** `Merged.md`**:** рекомендуется разделить документ на логические части:  
- **Введение:** кратко описать тему, цель обзора, границы рассмотрения (1 абзац).  
- **Основная часть:** разбить на разделы по подтемам (выявленным кластерам тезисов). В каждом разделе привести один или несколько сводных тезисов, подкрепить их данными/обоснованиями, указать применимость (из каких условий или источников они выведены).  
- **Заключение:** отметить оставшиеся неопределённости, противоречия или открытые вопросы, которые не удалось окончательно решить, с отсылкой на детали в отчёте (Audit). Например, упомянуть, какие утверждения требуют дальнейшей проверки, какие допущения влияют на выводы.

**Обязательный элемент** – ссылки на источники. Поскольку мы отслеживаем информацию через идентификаторы тезисов, целесообразно в финальном тексте после каждого ключевого утверждения ввести ссылки вида `[[C001, C014]]`, где перечислены ID исходных тезисов, из которых взята информация. Эти ссылки позволяют проследить происхождение каждого фрагмента знания. Дополнительно, если на шаге проверки фактов были внешние источники, можно оформить их как сноски или добавить к этим же ссылкам. Например, `[[C025][F3]]`, где `F3` – ссылка на внешний источник из `evidence.tsv`. В любом случае, текст должен быть **проверяемым** – любой факт может быть найден либо в приложенных исходниках, либо в указанных источниках.

**Пример промпта Synthesizer:**

> Ты – **Синтезатор**. Собери из проверенных тезисов финальный связный ответ. Возьми пересечение эквивалентных тезисов как базис (что подтверждено всеми – как твёрдые выводы). Добавь совместимые дополнения от разных вариантов, которые не противоречат базе, чтобы ответ был максимально полный. Соблюдай такие правила включения: (1) всё, что отмечено как `supported`, включай; (2) что отмечено как `conditional` – включай, но с явной оговоркой условий или области действия; (3) что `uncertain` или опровергнуто – **не включай** в основной текст, а вынеси в аудит. Если есть истинное противоречие между утверждениями, выбери для текста ту версию, которая подтверждена внешними источниками или более проверяема; альтернативную версию упомяни отдельно как опровергнутую либо устаревшую. Телеграфные куски расширь до понятных предложений, слишком многословные – сократи без потери смысла. В конце каждого абзаца проставь ссылки на исходники в формате \[\[C###, C###\]\].

После выполнения этого шага мы получим черновик `Merged.md`. В идеале, он уже будет финальным ответом, объединяющим лучшие части всех исходных текстов. Однако перед окончательным завершением проекта проводится ещё аудит – заключительная проверка соответствия и фиксация того, что включено или исключено.

*(Шаг 8 выполняется автоматически моделью, но* *только после* *того, как все противоречивые и неясные моменты отработаны на шагах 5–7. Оркестратор должен убедиться, что выполнены* стоп-условия*: в* `evidence.tsv` *и* `consistency.tsv` *проверены спорные зоны, и в* `conflicts.md` *не осталось нерешённых противоречий.)*

## Шаг 9: Автоматическое формирование отчёта (Auditor)

**Вход:** Все артефакты проекта: исходные тезисы, пары, результаты судейства, проверки, финальный текст.  
**Выход:** Файл-аудит `Audit.md` и обновлённый `conflicts.md` (с пометками о разрешении конфликтов).

Последний этап – **аудит** проделанной работы. Он служит двумя целям: во-первых, зафиксировать для пользователя или разработчика, *что именно вошло в финальный ответ, а что было отброшено* и по каким причинам; во-вторых, проверить целостность результата (финальная валидация может быть вынесена отдельно, но базовая отчетность – здесь). Audit.md – это документ, который можно приложить к результату, чтобы было прозрачно, как получен ответ.

В отчёте отразите следующие пункты: 1. **Удалённые фрагменты как риторические или несодержательные:** перечислите, какие части исходных документов были отброшены на этапе экстракции как несущие мало смысла (вводные слова, повторения, общие фразы). Можно указать их место (origin) и коротко причину (напр. «удалено вступление без фактов»).  
2. **Отклонённые тезисы и причины:** перечислите тезисы, которые не попали в итог, с указанием причин – были ли они опровергнуты фактчеком (`refuted`), признаны неустойчивыми (`uncertain`), устаревшими или выходящими за рамки вопроса. Каждому – ссылку (ID тезиса) и краткое объяснение.  
3. **Карта конфликтов и их разрешение:** возьмите список конфликтов из `conflicts.md` и отметьте, как каждый решён. Например: «Конфликт C12 vs C27 (данные по 2020 г.): решено в пользу C27, т.к. источник Всемирного банка подтвердил его данные, а C12 опровергнут (см. источник)…». Если какие-то противоречия так и остались нерешёнными, их тоже отметить (в финале не включены, но остаются открытыми вопросами).  
4. **Добавленные “long-tail” факты:** перечислите редкие, но ценные факты, которые были добавлены в финальный ответ из одного источника (то есть информация, уникальная для какого-то варианта, но обоснованная). Для каждого такого факта – откуда он взят (источник или тезис). Здесь же можно указать, если потребовались какие-то допущения или дополнительные небольшие данные для связности ответа.  
5. **Открытые вопросы и рекомендации:** перечислите, какие вопросы остались нерешёнными или какие ограничения выявлены. Например, «Нет данных по 2023 год – необходимо обновление, если появятся новые исследования», или «Модели расходятся в терминологии X, требуется уточнение определения в будущем». Это послужит планом для дальнейшей работы, если таковая будет.

**Формат Audit.md:** сочетание коротких пояснительных абзацев и табличных списков (для удобства). Каждое утверждение, упоминаемое в аудите, желательно снабжать ссылкой на идентификатор `C###` или на источник, чтобы было понятно, где оно фигурирует. Например: *«Тезис C45 исключён как* *uncertain* *– противоречивые данные (см. C12 vs C27 в conflicts)»*.

**Пример промпта Auditor:**

> Ты – **Аудитор**. Подготовь отчёт по итогам слияния: - Перечисли, что было **удалено как риторика или несущественное**, с указанием откуда (ID тезиса или место в документе) и почему. - Перечисли, **какие тезисы отклонены** (не вошли в ответ) и по какой причине – опровержение, неопределённость, дубликат, устарело и т.д. - Приведи **список конфликтов** из `conflicts.md` и опиши, как каждый разрешён (или не разрешён). - Отметь **редкие, но важные добавленные факты** («long-tail»), которые были включены в ответ, с указанием их источников. - Укажи **открытые вопросы** или ограничения, оставшиеся после этой работы, для возможной дальнейшей проверки. Оформи отчёт в Markdown с таблицами и ссылками на идентификаторы тезисов (C###) там, где это уместно. Будь краток и ясен в пояснениях.

После генерации Audit.md у вас будет полный набор результатов: `Merged.md` – финальный ответ, и `Audit.md` – сопроводительный отчёт, описывающий принятия решений. Эти материалы готовы для представления заказчику или для дальнейшего использования.

*(Шаг 9 также может выполняться моделью автоматически по шаблону. Проверка человеком желательна для убедительности, но в идеале отчёт формируется сразу правильно.)*

## Оркестрация процесса и минимизация запросов

Чтобы управлять всем описанным циклом с минимальными усилиями, рекомендуется использовать роль **Оркестратора**. Оркестратор не занимается содержательными выводами, а **контролирует последовательность шагов**, проверяет корректность артефактов и координирует передачу данных между этапами. В условиях chat.openai.com роль оркестратора, по сути, выполняет сам пользователь, задавая поочерёдно команды модели согласно этапам. Ниже – рекомендации, как оптимизировать управление:

- **Один запрос – один этап.** Структурируйте работу так, чтобы для запуска каждого шага достаточно было одной команды. Например: *«Теперь выполни роль Extractor для документов A и B…»*, затем после получения `claims.tsv` сказать *«Выполни нормализацию терминов…»* и т.д. Шаблоны промптов, приведённые выше, можно непосредственно использовать или слегка адаптировать под ваш запрос – они уже содержат все необходимые инструкции для модели.

- **Передача контекста.** Результаты каждого шага (таблицы TSV или списки) нужно подавать на вход следующему. В интерфейсе ChatGPT это можно делать, копируя релевантные части вывода модели или предоставляя модельному контексту полученные файлы. В будущем, когда инструменты позволят, оркестратор-агент сможет сам считывать файлы из хранилища и вызывать следующий подпроцесс, но пока это достигается пользовательскими действиями. Старайтесь не пропускать необходимые данные – например, на этапе судейства модели надо видеть тексты сравниваемых тезисов (их `claim` и `evidence_inline`), а на этапе синтеза – весь список подтверждённых тезисов и примечания к ним.

- **Проверки перед переходом к следующему шагу.** Оркестратор должен убедиться, что каждый артефакт заполнен корректно. Например, после Extractor: все тезисы имеют уникальные `id`, заполнено поле `origin`, указаны факты `[F#]`. Перед синтезом: нет неразобранных конфликтов (в `conflicts.md` все либо решены, либо помечены как открытые и вынесены в Audit). Если что-то критичное отсутствует, оркестратор останавливает процесс и возвращается к соответствующему шагу. В сложных случаях можно явно попросить модель-оркестратора проверить целостность артефактов – для этого есть специальный шаблон контроля (см. роль Orchestrator).

- **Минимизация ручного вмешательства.** Большинство шагов (Extract, Normalize, Blocking, Aligner, SelfCheck, Synthesizer, Auditor) **полностью автоматизируемы** – модель справляется с ними по заданному шаблону. Шаг **Judge** требует частичного участия: пользователь рандомизует порядок A/B и дважды запускает оценку, а затем может самостоятельно объединить результаты (или поручить это модели, но контролируемо). Шаг **Verifier** тоже может требовать помощи: хотя модель предложит вопросы, фактический веб-поиск может выполняться человеком или отдельным инструментом, затем ответы вводятся модели для оформления `evidence.tsv`. Если доступен плагин браузера или код-агент, этот шаг можно автоматизировать, но качество источников лучше контролировать вручную. Наконец, **QA/финальная валидация** (шаг 10, опционально) обычно проводится человеком – проверить, корректно ли расставлены ссылки, нет ли логических пробелов, соответствуют ли итоги целям проекта. Таким образом, **полная автоматизация** возможна при подключении инструментов и написании скрипта оркестратора (например, с наблюдением изменений файлов и вызовом ролей), но в интерфейсе ChatGPT более реалистичен полуавтоматический режим.

Ниже кратко перечислены стадии процесса и степень автоматизации каждой:

- **Шаг 1 (Extractor):** полностью автоматически моделирует извлечение тезисов по команде.
- **Шаг 2 (Normalizer):** автоматически нормализует термины.
- **Шаг 3 (Blocking):** автоматически формирует пары кандидатов.
- **Шаг 4 (Aligner/NLI):** автоматически классифицирует отношения пар (качество контролируется при необходимости).
- **Шаг 5 (Judge):** *частично автоматический* – модель выносит суждения, но требует от пользователя настройки «слепого» сценария и повторного прогона для объективности.
- **Шаг 6 (Verifier):** *частично автоматический* – модель генерирует вопросы и интерпретирует ответы, но интеграция с реальным веб-поиском может потребовать ручных действий или специализованных инструментов.
- **Шаг 7 (SelfCheck):** автоматическая проверка устойчивости формулировок.
- **Шаг 8 (Synthesizer):** автоматически генерирует финальный текст (при условии соблюдения всех предварительных условий).
- **Шаг 9 (Auditor):** автоматически составляет отчёт на основании всех данных.
- *(Шаг 10 – финальная проверка качества (QA) – при необходимости выполняется вручную или отдельным агентом, чтобы принять результат или указать на недочёты.)*

При следовании этой инструкции пользователь может управлять сложным пайплайном **минимальными запросами**, добиваясь от модели выполнения строго очерченных задач на каждом этапе. В реальных проектах рекомендуется после одного полного цикла зафиксировать окончательно доработанные промпты для всех ролей и форматы – это станет *спецификацией* системы, которую затем можно реализовать программно или повторно использовать без изменений на схожих задачах.

## Форматы файлов данных

Для удобства интеграции и последующей автоматизации все промежуточные артефакты хранятся в табличных текстовых файлах (TSV, Markdown таблицы). Ниже приведены форматы основных файлов (названия столбцов):

- **claims.tsv** – тезисы после экстракции (и нормализации). Колонки: `id` – уникальный идентификатор; `claim` – текст тезиса; `evidence_inline` – встроенное доказательство/пример; `scope.time` – временной охват; `scope.jurisdiction` – юрисдикция/область; `scope.conditions` – условия; `facts` – фактические маркеры (F#); `origin` – источник (документ и место в нём); `notes` – примечания.

- **term_map.tsv** – таблица терминов для нормализации. Колонки: `canonical` – канонический термин; `variants` – варианты написания/перевода; `lang` – язык/тип; `definition_source` – ссылка на определение (если нужно); `notes` – комментарии.

- **pairs.tsv** – пары тезисов для сравнения (после блокинга и дополненные отношениями). Колонки: `pair_id`; `A_id`; `B_id`; `matched_keys` (ключевые совпадения); `scope_overlap` (пересечение условий); *(после шага 4 добавляются:)* `relation` (тип отношения); `nli` (логический статус); `rationale` (обоснование отношения); `conflict_type` (тип конфликта, если есть); `condition_notes` (заметки по условиям).

- **judgments.tsv** – результаты судейства пар. Колонки: `pair_id`; `winner` (победитель A/B или ничья); `C1`; `C2`; `C3`; `C4`; `C5` (оценки по критериям или пометки, в зависимости от формата – можно `+/-` или `yes/no` с пояснениями); `notes` – обобщающий комментарий. *(Если критериев 4, то C5 отсутствует.)*

- **evidence.tsv** – проверенные факты и источники (Chain-of-Verification). Колонки: `claim_id` (какого тезиса касается вопрос); `question` (вопрос к поиску); `status` (`supported/refuted/uncertain`); `source` (название источника и/или URL); `date` (дата источника); `quote` (краткая цитата).

- **consistency.tsv** – результат SelfCheck. Колонки: `claim_id`; `variants_diff` (различия между сгенерированными вариантами формулировок); `unstable_facts` (список фактов, которые менялись); `decision` (`stable` или `uncertain`).

- **conflicts.md** – (Markdown-документ) список конфликтов между тезисами. Формат записи может быть произвольным, например, список пунктов: каждый конфликт с указанием тезисов (A_id vs B_id) и кратким описанием противоречия или различия условий, а также тип конфликта. После разрешения конфликтов оркестратор может проставить отметки, как они разрешены или где отражены (например, "решён в пользу ...", "вынесено в Audit.md" и т.п.).

- **Merged.md** – итоговый слитый ответ (Markdown). Структура описана выше: включает разделы, абзацы с утверждениями, *внутритекстовые ссылки* на тезисы `[[C#]]` и оформленные библиографические ссылки на внешние источники (если используются), плюс возможно сноски.

- **Audit.md** – аудиторский отчёт (Markdown). Содержит таблицы/списки по пунктам (1)–(5), упомянутым в шаге 9. Обязательно наличие идентификаторов тезисов или номеров источников для каждого пункта, чтобы была прослеживаемость.

- *(Опционально:)* **claim_ledger.json** – машиночитаемый журнал тезисов и их связей. Структура по усмотрению (например, граф связей, статусы), если требуется интеграция с другими системами.

Каждый файл следует хранить в соответствующей папке (например, `data/claims.tsv`, `output/Merged.md` и т.д.) – так будет проще автоматизировать мониторинг и запуск следующих ролей при наличии код-агента.

При правильном следовании всем шагам и форматам, данный пайплайн позволит гибко объединять несколько разных по стилистике и содержанию текстов в единый проверенный документ. Он сочетает сильные стороны различных подходов ИИ: поиск истин через сравнение (debate), гарантии фактов через верификацию, и генеративный синтез для финальной компоновки ответа. Полученная инструкция и шаблоны готовы к непосредственному применению с минимальными изменениями под конкретную предметную область – достаточно подставить свои тексты и следовать шагам, либо реализовать оркестрацию программно. Все решения, принятые в процессе (что включено, что опущено и почему), задокументированы в Audit.md, что повышает доверие к результату и упрощает его проверку.

**Sources:** Использованы материалы спецификации LLM-Text-Compare и аналитических заметок, отражающих лучшие практики реализации подобного проекта.
