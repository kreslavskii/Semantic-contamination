# Пример конфигурации для Semantic Contamination
# Скопируйте этот файл в .env и заполните своими ключами
# cp .env.example .env

# ============================================
# LLM API Keys
# ============================================

# OpenAI API (https://platform.openai.com/api-keys)
OPENAI_API_KEY=sk-...

# Anthropic API (https://console.anthropic.com/)
ANTHROPIC_API_KEY=sk-ant-...

# ============================================
# Web Search API
# ============================================

# SerpAPI для веб-поиска (https://serpapi.com/)
SERPAPI_API_KEY=your_serpapi_key_here

# ============================================
# Model Settings
# ============================================

# Выбор провайдера LLM: openai | anthropic
DEFAULT_LLM_PROVIDER=openai

# Модель для использования
# OpenAI: gpt-4-turbo-preview, gpt-4, gpt-3.5-turbo
# Anthropic: claude-3-opus-20240229, claude-3-sonnet-20240229
DEFAULT_MODEL=gpt-4-turbo-preview

# Температура для generation (0.0 = детерминированный, 1.0 = креативный)
TEMPERATURE=0.7

# Максимальное количество токенов в ответе
MAX_TOKENS=2000

# ============================================
# Agent Settings
# ============================================

# Использовать PairRM для JudgeAgent (true/false)
USE_PAIRRM=true

# Использовать SelfCheckGPT для ExtractorAgent (true/false)
USE_SELFCHECK=true

# Количество samples для SelfCheck (3-5 рекомендуется)
SELFCHECK_SAMPLES=3

# Double-check для JudgeAgent (проверка в обратном порядке)
JUDGE_DOUBLE_CHECK=true

# ============================================
# Cost & Rate Limits
# ============================================

# Максимальная стоимость одного запуска пайплайна (USD)
MAX_COST_PER_RUN=10.0

# Максимальное количество API вызовов в минуту
MAX_REQUESTS_PER_MINUTE=60

# Таймаут для API запросов (секунды)
API_TIMEOUT=30

# ============================================
# Logging
# ============================================

# Уровень логирования: DEBUG | INFO | WARNING | ERROR | CRITICAL
LOG_LEVEL=INFO

# Путь к файлу логов (оставьте пустым для вывода в консоль)
LOG_FILE=

# ============================================
# Paths
# ============================================

# Директория с входными документами
INPUT_DIR=data

# Директория для результатов
OUTPUT_DIR=output

# Директория с промптами
PROMPTS_DIR=prompts

# ============================================
# Performance
# ============================================

# Использовать GPU для локальных моделей (PairRM, SelfCheck)
USE_GPU=true

# Количество worker threads для параллельной обработки
NUM_WORKERS=4

# Размер батча для batch processing
BATCH_SIZE=10

# ============================================
# Cache Settings
# ============================================

# Кэшировать LLM ответы для экономии (true/false)
ENABLE_CACHE=true

# Время жизни кэша (секунды)
CACHE_TTL=3600

# Директория для кэша
CACHE_DIR=.cache

# ============================================
# Development
# ============================================

# Debug mode (выводит дополнительную информацию)
DEBUG=false

# Dry run (не делает реальные API вызовы, использует моки)
DRY_RUN=false
